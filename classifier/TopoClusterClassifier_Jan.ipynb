{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification of ATLAS Calorimeter Topo-Clusters (Jan)\n",
    "\n",
    "This is a stripped-down version of Max's re-write of his classifier training notebook, so I have removed *some* functionality like ROC curve scans. These could be added back in the future (using the code from his notebooks, maybe put into our library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'pion'\n",
    "subdir = 'pion_full' # name for subdir holding models/plots\n",
    "h5_name_suffix = 'tdata_large' # used for HDF5 files containing selected events, indices\n",
    "\n",
    "# If true, force re-training even if a model already exists. Existing model will be lost!\n",
    "overwriteModel = False\n",
    "\n",
    "# If true, continue training and try to train to the last specified epoch.\n",
    "# If EarlyStopping was used, this may result in trying to further train a \"finished\" network.\n",
    "finishTraining = False\n",
    "\n",
    "drawPlots = True\n",
    "\n",
    "# If no file extension, uses native TensorFlow format (.tf).\n",
    "# If 'h5', uses HDF5. HDF5 does not work for custom layers/classes! (unless you design them a certain way)\n",
    "file_extension = '.h5'\n",
    "if(file_extension != '' and '.' not in file_extension):\n",
    "    file_extension = '.' + file_extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Navigation:\n",
    "- [Simple feed-forward Neural Network](#Simple-feed-forward-Neural-Network)\n",
    "- [Combination Network](#Combination-Network)\n",
    "- [Convolutional Neural Networks](#Convolutional-Neural-Networks)\n",
    "    - [Single-calo-layer CNN](#Single-calo-layer-CNN's)\n",
    "    -[Combination Network (CNN's)](#Combination-Network:-Take-2)\n",
    "    - [Complex CNN's](#Convolutional-Neural-Networks:-More-complicated-architectures)\n",
    "        - [3 EMB layers, separate](#3-EMB-layers,-separate)\n",
    "        - [All layers, separate](#All-layers,-separate)\n",
    "        - [All layers, merged](#All-layers,-merged)\n",
    "        - [EMB merged + TileBar merged](#EMB-merged-+-TileBar-merged)\n",
    "        - [EMB merged + TileBar depth](#EMB-merged-+-TileBar-depth)\n",
    "        - [EMB1 + (EMB2+EMB3) + TileBar merged](#EMB1,-EMB2+EMB3,-and-TileBar)\n",
    "- [ResNet](#ResNet)\n",
    "- [Combination Network (ResNet + simple NN)](#Combination-Network:-Take-3)\n",
    "\n",
    "- [Summary Plots](#Summary-Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/00\n"
     ]
    }
   ],
   "source": [
    "#import libraries and some constants\n",
    "import os, sys, json, pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ROOT as rt # I will use this for some plotting\n",
    "import uproot as ur\n",
    "\n",
    "path_prefix = os.getcwd() + '/../'\n",
    "plotpath = path_prefix+'classifier/Plots/{}/'.format(subdir)\n",
    "modelpath = path_prefix+'classifier/Models/{}/'.format(subdir)\n",
    "\n",
    "for dir in [plotpath,modelpath]:\n",
    "    try:os.makedirs(dir)\n",
    "    except: pass\n",
    "\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu\n",
    "from util import qol_util as qu\n",
    "\n",
    "# Custom tensorflow.keras callbacks\n",
    "from util.keras.callbacks import GetCallbacks\n",
    "\n",
    "# Classification-specific utils\n",
    "from util.classification import training_util as ctu\n",
    "from util.classification import plot_util as cpu\n",
    "from util.classification import data_util as cdu\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "cell_shapes = {layers[i]:(len_eta[i],len_phi[i]) for i in range(len(layers))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy display names for each pion type\n",
    "pi_latex = {\n",
    "    'p0': '\\(\\pi^{0}\\)',\n",
    "    'pp': '\\(\\pi^{\\pm}\\)',\n",
    "}\n",
    "pi_text = {\n",
    "    'p0': 'pi0',\n",
    "    'pp': 'pi+/-'\n",
    "}\n",
    "\n",
    "# Plotting settings\n",
    "# xkcd -- turn this on for fun-looking (but marginally less useful) plots\n",
    "use_xkcd = False\n",
    "if(use_xkcd):\n",
    "    mode = 'light'\n",
    "    plt.xkcd(scale=.75,length=100,randomness=1)\n",
    "    \n",
    "# plotting style -- manages our color palette and object colors\n",
    "mode = 'dark' # for publications, use \"light\"\n",
    "plotstyle = qu.PlotStyle(mode)\n",
    "    \n",
    "# some matplotlib-specific stuff\n",
    "params = {'legend.fontsize': 13,\n",
    "          'axes.labelsize': 18}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import our data from the `ROOT` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(source == 'pion_legacy'):\n",
    "    inputpath = path_prefix+'data/pion_legacy/'\n",
    "    rootfiles = {\n",
    "        'p0':inputpath + 'pi0.root',\n",
    "        'pp':inputpath + 'pi[pm]*.root'\n",
    "    }\n",
    "    branches = [\n",
    "                'clusterE', 'clusterECalib', \n",
    "                'clusterPt', 'clusterEta', 'clusterPhi', \n",
    "                'cluster_nCells', 'cluster_sumCellE', \n",
    "                'cluster_ENG_CALIB_TOT', 'cluster_EM_PROBABILITY'\n",
    "    ]\n",
    "\n",
    "elif(source == 'pion'):\n",
    "    inputpath=path_prefix+'data/pion/'\n",
    "    rootfiles = {        \n",
    "        'p0':inputpath + 'user.mswiatlo.900246.PG_singlepi0_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root',\n",
    "        'pp':inputpath + 'user.mswiatlo.900247.PG_singlepion_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root'\n",
    "    }\n",
    "    branches = [\n",
    "                'clusterE', 'clusterECalib', \n",
    "                'clusterPt', 'clusterEta', 'clusterPhi', \n",
    "                'cluster_nCells', 'cluster_sumCellE', \n",
    "                'cluster_ENG_CALIB_TOT', 'cluster_EM_PROBABILITY'\n",
    "    ]    \n",
    "\n",
    "elif(source == 'pion_converted'):\n",
    "    inputpath = path_prefix+'data/pion_converted/'\n",
    "    rootfiles = {\n",
    "        'p0':inputpath + 'user.angerami.mc16_13TeV.900246.PG_singlepi0_logE0p2to2000.e8312_e7400_s3170_r12383.v01-45-gaa27bcb_OutputStream/*.root',\n",
    "        'pp':inputpath + 'user.angerami.mc16_13TeV.900247.PG_singlepion_logE0p2to2000.e8312_e7400_s3170_r12383.v01-45-gaa27bcb_OutputStream/*.root'\n",
    "    }\n",
    "    branches = [\n",
    "        'cluster_E', 'cluster_E_LCCalib', \n",
    "        'cluster_Pt', 'cluster_Eta', 'cluster_Phi', \n",
    "        'cluster_nCells',\n",
    "        'cluster_ENG_CALIB_TOT', 'cluster_EM_PROBABILITY'\n",
    "    ]\n",
    "    \n",
    "else: assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pandas DataFrame and calo images from /local/home/jano/ml4pions/LCStudies/classifier/../data/pion/tdata_frame.h5 and /local/home/jano/ml4pions/LCStudies/classifier/../data/pion/tdata_images.h5.\n",
      "Number of pi0     events:     300000\t(50.0%)\n",
      "Number of pi+/-   events:     300000\t(50.0%)\n",
      "Total: 600000\n",
      "Loading indices for key p0 from /local/home/jano/ml4pions/LCStudies/classifier/../data/pion/tdata_indices.h5.\n",
      "Loading indices for key pp from /local/home/jano/ml4pions/LCStudies/classifier/../data/pion/tdata_indices.h5.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "h5_name = inputpath + h5_name_suffix\n",
    "\n",
    "pdata,pcells = mu.setupPionData(\n",
    "    rootfiles, \n",
    "    branches=branches, \n",
    "    layers=layers, \n",
    "    balance_data=True, \n",
    "    n_max = 300000,\n",
    "    verbose=True,\n",
    "    load=True,\n",
    "    save=True,\n",
    "    filename=h5_name,\n",
    "    match_distribution='cluster_ENG_CALIB_TOT',\n",
    "    match_binning = (20000,0.,2000.),\n",
    "    cut_distributions=['cluster_ENG_CALIB_TOT','clusterEta'],\n",
    "    cut_values = [.2, (-0.7,0.7)],\n",
    "    cut_types=['lower','window']\n",
    ")\n",
    "\n",
    "total = np.sum([len(x) for x in pdata.values()],dtype=int)\n",
    "for key,frame in pdata.items():\n",
    "    n = len(frame)\n",
    "    print(\"Number of {a:<7} events: {b:>10}\\t({c:.1f}%)\".format(a=pi_text[key], b = n, c = 100. * n / total))\n",
    "print(\"Total: {}\".format(total))\n",
    "\n",
    "pdata_merged, pcells_merged, plabels = cdu.DataPrep(pdata, \n",
    "                                                    pcells, \n",
    "                                                    layers, \n",
    "                                                    trainfrac=0.7,\n",
    "                                                    filename=h5_name\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the network on $\\pi^+$ and $\\pi^0$ events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a few example images.\n",
    "\n",
    "These are the images that we will use to train our network (together with a few other variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_idx = 50 # pick a cluster from our dataset to draw\n",
    "cpu.ImagePlot(\n",
    "    pcells,\n",
    "    cluster=cluster_idx,\n",
    "    layers=layers,\n",
    "    cell_shapes=cell_shapes,\n",
    "    plotpath=plotpath,\n",
    "    filename='calo_images.png',\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "scaled_shape = (16,16)\n",
    "cpu.ImagePlot(\n",
    "    pcells,\n",
    "    cluster=cluster_idx,\n",
    "    scaled_shape=scaled_shape,\n",
    "    layers=layers,\n",
    "    cell_shapes=cell_shapes,\n",
    "    plotpath=plotpath,\n",
    "    filename='calo_images_{}x{}.png'.format(*scaled_shape),\n",
    "    plotstyle=plotstyle\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a few histograms.\n",
    "\n",
    "These are a bit uglier than the `matplotlib` ones Max made, but it's perhaps even easier to see any differences between $\\pi^\\pm$ and $\\pi^0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.gStyle.SetOptStat(0)\n",
    "plotstyle.SetStyle()\n",
    "\n",
    "#if(drawPlots):\n",
    "# For storing histograms and legends, to prevent overwriting. (TODO: Probably better ways to do this in PyROOT)\n",
    "histos = []\n",
    "legends = []\n",
    "\n",
    "# Exhaustive list of quantities we want to plot. Note that some will not be available, depending on dataset provenance/age.\n",
    "n_bins_small = 20\n",
    "n_bins_med = 100\n",
    "n_bins_large = int(2e4)\n",
    "qtys = [\n",
    "    ('cluster_nCells','Cells/Cluster',(n_bins_med,0,1000)),\n",
    "    ('clusterE','cluster Energy [GeV]',(n_bins_large,1.0e-2,2.0e3)),\n",
    "    ('cluster_E','cluster Energy [GeV]',(n_bins_large,1.0e-2,2.0e3)),\n",
    "    ('clusterEta','cluster #eta',(n_bins_small,-4.,4.)),\n",
    "    ('cluster_Eta','cluster #eta',(n_bins_small,-4.,4.)),\n",
    "    ('clusterPhi','cluster #phi',(n_bins_small,-4.,4.)),\n",
    "    ('cluster_Phi','cluster #phi',(n_bins_small,-4.,4.)),\n",
    "    ('cluster_EM_PROBABILITY','cluster EMProb',(n_bins_small,0.,1.)),\n",
    "    #('cluster_sumCellE','cluster SumCellE',(n_bins_small,0.,2500.)),\n",
    "    ('cluster_ENG_CALIB_TOT','cluster E^{calib}_{tot}',(n_bins_large,1.0e-2,2.0e3))\n",
    "]\n",
    "\n",
    "log_x = ['clusterE', 'cluster_E', 'cluster_ENG_CALIB_TOT']\n",
    "log_y = ['cluster_nCells','clusterE', 'cluster_E', 'cluster_EM_PROBABILITY', 'cluster_sumCellE', 'cluster_ENG_CALIB_TOT']\n",
    "\n",
    "qtys = [x for x in qtys if x[0] in branches]\n",
    "\n",
    "qty_labels = [x[1] for x in qtys]\n",
    "qty_ranges = [x[2] for x in qtys]\n",
    "qtys =       [x[0] for x in qtys]\n",
    "\n",
    "# Set up a canvas.\n",
    "plot_size = 500\n",
    "nx = int(np.ceil(len(qtys) / 2))\n",
    "ny = 2\n",
    "n_pad = nx * ny\n",
    "canvas = rt.TCanvas('cluster_hists','c1',plot_size * nx,plot_size * ny)\n",
    "canvas.Divide(nx,ny)\n",
    "\n",
    "colors = {'pp':rt.kRed,'p0':rt.kBlue}\n",
    "styles = {'pp':3440, 'p0':3404}\n",
    "\n",
    "n_bins=20\n",
    "for i, (qty, label, rng) in enumerate(zip(qtys, qty_labels, qty_ranges)):\n",
    "    canvas.cd(i+1)\n",
    "    leg = rt.TLegend(0.7,0.8,0.9,0.9)\n",
    "    for ptype, p in pdata.items():\n",
    "        hist = rt.TH1F('h_'+str(ptype)+'_'+str(qty),'',rng[0],rng[1],rng[2])\n",
    "        for entry in p[qty]: hist.Fill(entry)\n",
    "        integral = hist.Integral()\n",
    "        if(integral != 0): hist.Scale(1./hist.Integral())\n",
    "        hist.SetLineColor(colors[ptype])\n",
    "        hist.SetLineWidth(2)\n",
    "\n",
    "        if(qty not in log_x):\n",
    "            hist.SetFillColorAlpha(colors[ptype],0.5)\n",
    "            hist.SetFillStyle(styles[ptype])\n",
    "\n",
    "        hist.Draw('HIST SAME')\n",
    "        hist.GetXaxis().SetTitle(label)\n",
    "        hist.GetYaxis().SetTitle('Normalised events')\n",
    "        hist.SetMaximum(1.5 * hist.GetMaximum())\n",
    "        leg.AddEntry(hist,pi_latex[ptype],'f')\n",
    "        leg.Draw()\n",
    "        histos.append(hist)\n",
    "        legends.append(leg)\n",
    "\n",
    "    if(qty in log_x): rt.gPad.SetLogx()\n",
    "    if(qty in log_y): rt.gPad.SetLogy()\n",
    "canvas.Draw()\n",
    "\n",
    "canvas.SaveAs(plotpath+'hist_pi0_plus_minus.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow/Keras prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Starting in May 2021, I've run into some issues with `tensorflow`/`tensorflow-gpu` not detecting/using GPU's. This issue is documented in a number of places, including [here](https://github.com/ContinuumIO/anaconda-issues/issues/12194). The current fix is to use an older version of `tensorflow` (and downgrading things is seldom a satisfying solution).\n",
    "\n",
    "You can check GPU usage using `nvidia-smi`. Note that it appears to immediately show a python process using memory after running the setup cell below. Once training begins, you can check that this is actually being used by monitoring power consumption and volatile GPU memory usage (which should increase noticeably once you start actual training). TensorFlow may still print out info about broadcasting things to CPU, which by itself isn't an issue or sign that the GPU is not being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-28 16:34:02.697820: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-06-28 16:34:02.702512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-28 16:34:02.752877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro P5000 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 269.00GiB/s\n",
      "2021-06-28 16:34:02.752967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-28 16:34:02.757629: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-28 16:34:02.757782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-28 16:34:02.759620: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-28 16:34:02.759997: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-28 16:34:02.761710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-28 16:34:02.762653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-28 16:34:02.762907: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-06-28 16:34:02.762921: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-06-28 16:34:02.766759: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-28 16:34:02.769906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-28 16:34:02.769948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-06-28 16:34:02.769965: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "ngpu = 1\n",
    "gpu_list = [\"/gpu:\"+str(i) for i in range(ngpu)]\n",
    "#gpu_list = [\"/gpu:0\"] #[\"/gpu:0\",\"/gpu:1\",\"/gpu:2\",\"/gpu:3\"]\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disable some of the tensorflow info printouts, only display errors\n",
    "import tensorflow as tf\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list) # if running into issues, see https://stackoverflow.com/questions/54766621/mirroredstrategy-doesnt-use-gpus\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))\n",
    "from util.classification.models import baseline_nn_model, baseline_cnn_model, emb_cnn_model, all_cnn_model, merged_cnn_model, merged_cnn_2p_model, resnet, simple_combine_model\n",
    "from util.classification.models_exp import exp_cnn_model, exp_merged_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare some callbacks (originally from our regression notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storing models and some of their metrics (acc, loss)\n",
    "models = {}\n",
    "model_history = {}\n",
    "model_scores = {}\n",
    "model_performance = {}\n",
    "\n",
    "# For storing info on ROC curves\n",
    "roc_fpr = {}\n",
    "roc_tpr = {}\n",
    "roc_thresh = {}\n",
    "roc_auc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's add some info to our dictionaries that corresponds to the existing `EM LC Prob` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = 'LC EMProb'\n",
    "model_scores[model_key] = 1-pdata_merged[\"cluster_EM_PROBABILITY\"]\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    drawPlots=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple feed-forward Neural Network\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to train simple, feed-foward neural networks -- one per calo layer. These will be our \"baseline networks\".\n",
    "\n",
    "Note that while for most of the notebook, we'll train one instance of a network per model, whereas here we will explicitly train multiple instances as we're doing one instance *per calo layer*, each for the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "gamma = 0.1\n",
    "min_delta = 0.0001\n",
    "patience = 3\n",
    "dropout = 0.1 # < 0 -> no dropout\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "\n",
    "model_name = 'flat'\n",
    "model_dir = modelpath + model_name # directory for loading/saving flat models\n",
    "\n",
    "for layer in layers:\n",
    "    \n",
    "    model_key = '{}_{}'.format(model_name, layer)\n",
    "    modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "    npix = cell_shapes[layer][0] * cell_shapes[layer][1]\n",
    "    models[model_key] = baseline_nn_model(strategy, npix, lr=lr, dropout=dropout, normalization=normalization)\n",
    "    \n",
    "    # train the network\n",
    "    models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "        model=models[model_key], \n",
    "        modelfile=modelfile, \n",
    "        x_train = pcells_merged[layer][pdata_merged.train], \n",
    "        y_train = plabels[pdata_merged.train], \n",
    "        x_valid = pcells_merged[layer][pdata_merged.val], \n",
    "        y_valid = plabels[pdata_merged.val], \n",
    "        callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "        epochs=nepochs, \n",
    "        batch_size=batch_size, \n",
    "        verbose=verbose, \n",
    "        overwriteModel=overwriteModel,\n",
    "        finishTraining=finishTraining\n",
    "    )\n",
    "        \n",
    "    # get performance metric from test set\n",
    "    model_performance[model_key] = models[model_key].evaluate(\n",
    "        pcells_merged[layer][pdata_merged.test],\n",
    "        plabels[pdata_merged.test],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print('Finished layer {}.'.format(layer))\n",
    "    \n",
    "    # get/recalculate network scores for the dataset\n",
    "    model_scores[model_key] = models[model_key].predict(pcells_merged[layer])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at accuracy and loss, as well as ROC curves, for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_flat',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Network\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train a simple combination network. Its inputs will be the *outputs* of our simple, feed-forward neural networks from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'simple'\n",
    "model_dir = modelpath + model_name # directory for loading/saving simple combination network\n",
    "model_key = 'simpleCombine'\n",
    "\n",
    "model_scores_stack = np.column_stack( [model_scores['flat_{}'.format(layer)] for layer in layers])\n",
    "n_input = model_scores_stack.shape[1]\n",
    "\n",
    "lr = 1e-3\n",
    "gamma = 0.1\n",
    "min_delta = 0.0005\n",
    "patience = 5\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key,file_extension)\n",
    "models[model_key] = simple_combine_model(strategy, lr=lr, n_input=n_input)\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = model_scores_stack[pdata_merged.train],\n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = model_scores_stack[pdata_merged.val], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    model_scores_stack[pdata_merged.test],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(model_scores_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys = ['simpleCombine'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_simple',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = ['LC EMProb', 'flat_EMB1', 'simpleCombine']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "Let's try some convolutional neural networks -- afterwards we'll also try an implementation of ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-calo-layer CNN's\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "First up, we can try creating a set of CNN's, where each only uses an image from a single calorimeter layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-5\n",
    "gamma = 0.1\n",
    "min_delta = 0.0001\n",
    "patience = 3\n",
    "augmentation = True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "\n",
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving flat models\n",
    "\n",
    "filters = {\n",
    "    'EMB1': (2,4), \n",
    "    'EMB2': (4,4), \n",
    "    'EMB3': (4,2), \n",
    "    'TileBar0': (2,2), \n",
    "    'TileBar1': (2,2), \n",
    "    'TileBar2': (1,1)\n",
    "}\n",
    "pools = {\n",
    "    'EMB1': (1,1), \n",
    "    'EMB2': (2,2), \n",
    "    'EMB3': (1,1), \n",
    "    'TileBar0': (1,1), \n",
    "    'TileBar1': (1,1), \n",
    "    'TileBar2': (1,1)\n",
    "}\n",
    "\n",
    "for layer in layers:\n",
    "    model_key = '{}_{}'.format(model_name, layer)\n",
    "    modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)    \n",
    "    models[model_key] = baseline_cnn_model(input_shape=cell_shapes[layer], f=filters[layer], pool=pools[layer], lr=lr, augmentation=augmentation, normalization=normalization)\n",
    "    \n",
    "    # train the network\n",
    "    models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "        model=models[model_key], \n",
    "        modelfile=modelfile, \n",
    "        x_train = rn_data['train'][layer], \n",
    "        y_train = plabels[pdata_merged.train], \n",
    "        x_valid = rn_data['valid'][layer],\n",
    "        y_valid = plabels[pdata_merged.val], \n",
    "        callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "        epochs=nepochs, \n",
    "        batch_size=batch_size, \n",
    "        verbose=verbose, \n",
    "        overwriteModel=overwriteModel,\n",
    "        finishTraining=finishTraining\n",
    "    )\n",
    "        \n",
    "    # get performance metric from test set\n",
    "    model_performance[model_key] = models[model_key].evaluate(\n",
    "        rn_data['test'][layer],\n",
    "        plabels[pdata_merged.test],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print('Finished layer {}.'.format(layer))\n",
    "    \n",
    "    # get/recalculate network scores for the dataset\n",
    "    model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened[layer])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    plotstyle=plotstyle,\n",
    "    model_keys = ['cnn_{}'.format(layer) for layer in layers]\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = ['cnn_{}'.format(layer) for layer in layers]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination Network: Take 2\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "Let's try another combination network, using our single layer CNN's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'simple_cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving simple combination network\n",
    "model_key = 'simpleCombine_cnn'\n",
    "\n",
    "model_scores_stack = np.column_stack([model_scores['cnn_{}'.format(layer)] for layer in layers])\n",
    "n_input = model_scores_stack.shape[1]\n",
    "\n",
    "lr = 1e-3\n",
    "gamma = 0.1\n",
    "min_delta = 0.0001\n",
    "patience = 3\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key,file_extension)\n",
    "models[model_key] = simple_combine_model(strategy, lr=lr, n_input=n_input)\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = model_scores_stack[pdata_merged.train],\n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = model_scores_stack[pdata_merged.val], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    model_scores_stack[pdata_merged.test],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(model_scores_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    plotstyle=plotstyle,\n",
    "    model_keys = ['simpleCombine_cnn']\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_simple_cnn',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = ['LC EMProb', 'simpleCombine', 'simpleCombine_cnn']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks: More complicated architectures\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "We can also consider more complex CNN's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 EMB layers, separate\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "First, we can try one that uses all three EMB layers as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "# keep only the EMB layers\n",
    "pcells_merged_unflattened = {key:pcells_merged_unflattened[key] for key in ['EMB1','EMB2','EMB3']}\n",
    "\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_EMB_all'\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation=True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = emb_cnn_model(\n",
    "    lr=lr,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_EMB_all'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_EMB_all',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'simpleCombine_cnn', 'cnn_EMB_all']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All layers, separate\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "Similarly, we can try a network using all six calo layers, as separate 1-channel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_all'\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation=True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = all_cnn_model(\n",
    "    lr=lr,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_all'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_all',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'simpleCombine_cnn', 'cnn_EMB_all', 'cnn_all']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All layers, merged\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "Of course, we can also treat the 6 calo layers as 6 channels of the *same* image. Note that this will require some rescaling of the images so that their dimensions match -- we'll also be careful to preserve their integrals. This last point is probably even more relevant for regression tasks (i.e. predicting energy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_merged'\n",
    "\n",
    "input_shape = (16,16)\n",
    "dropout = 0.2\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation = True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = merged_cnn_model(\n",
    "    lr=lr,\n",
    "    input_shape=input_shape,\n",
    "    dropout=dropout,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_merged'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_merged',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'simpleCombine_cnn', 'cnn_EMB_all', 'cnn_all', 'cnn_merged']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMB merged + TileBar merged\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "As another variation on this theme, we can try a \"merged\" CNN where we separately treat the 3 EMB layers and the 3 TileBar layers. This will allow us to perform separate rescalings for each -- and we may thus be able to have fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_merged_2p'\n",
    "\n",
    "input_shape1 = (16,16)\n",
    "input_shape2 = (4,4)\n",
    "dropout = 0.2\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation = True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = merged_cnn_2p_model(\n",
    "    lr=lr,\n",
    "    input_shape1=input_shape1,\n",
    "    input_shape2=input_shape2,\n",
    "    dropout=dropout,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_merged_2p'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_merged_2p',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'cnn_merged', 'cnn_merged_2p']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMB merged + TileBar depth\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "As an experiment, we can try a network where we use a CNN approach for the EMB layers, whereas for TileBar we just use the integrals of the 3 Tilebar layers. In other words, we don't fully use TileBar images, but just get some depth info from how populated they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_exp'\n",
    "\n",
    "input_shape = (16,16)\n",
    "dropout = 0.2\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation = True\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = exp_cnn_model(\n",
    "    lr=lr,\n",
    "    input_shape=input_shape,\n",
    "    dropout=dropout,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_exp'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_exp',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'cnn_merged', 'cnn_merged_2p', 'cnn_exp']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMB1, EMB2+EMB3, and TileBar\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "As another experiment, we can try a network where we use a CNN approach for all layers, but we combine things a little differently. Rather than combine all EMB and all TileBar layers, we separate EMB into EMB1, and (EMB2 + EMB3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=True)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")\n",
    "rn_data = {key: list(val.values()) for key,val in rn_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'cnn_split_EMB'\n",
    "\n",
    "dropout = 0.2\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 10\n",
    "augmentation = False\n",
    "normalization = True # normalize calo images to unit integral\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = exp_merged_model(\n",
    "    lr=lr,\n",
    "    dropout=dropout,\n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['cnn_split_EMB'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_cnn_split_EMB',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'cnn_merged', 'cnn_merged_2p', 'cnn_exp', 'cnn_split_EMB']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "We can also train an instance of ResNet. As with our multi-layer CNN's, we'll need to perform some up/downscaling of images, so that they all have the same dimensions. As we did for some of our CNN's, we will use the maximum possible granularity, `(128,16)` (corresponding with maximum eta and phi dimensions among all calo layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcells_merged_unflattened = cdu.ReshapeImages(pcells_merged, cell_shapes, use_layer_names=False)\n",
    "rn_data = cdu.DictionarySplit(\n",
    "    pcells_merged_unflattened, \n",
    "    train_indices=pdata_merged.train,\n",
    "    validation_indices = pdata_merged.val,\n",
    "    test_indices = pdata_merged.test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a quick test to make sure that our image scaling is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test=False\n",
    "\n",
    "from util.keras.layers import ImageScaleBlock\n",
    "def TestImage(idxs):\n",
    "    images = [np.stack([rn_train['input{}'.format(x)][idx,:,:] for idx in idxs],axis=0) for x in range(6)]    \n",
    "    # need to add the last dimension, corresponding with channel (will be of size 1)\n",
    "    images = [np.expand_dims(im, axis=-1) for im in images]\n",
    "    return images\n",
    "\n",
    "if(image_test):\n",
    "    test_idx = np.arange(5)\n",
    "    image = TestImage(test_idx)\n",
    "    scaled_image = ImageScaleBlock((128,16),normalization=True)(image).numpy()\n",
    "    for i,im in enumerate(image):\n",
    "        integrals_old = np.sum(im,axis=(1,2)).flatten()\n",
    "        integrals_new = np.sum(scaled_image[:,:,:,i], axis=(1,2)).flatten()\n",
    "\n",
    "        ratio = integrals_old.copy()\n",
    "        ratio[ratio==0.] = 1.\n",
    "        ratio = integrals_new/ratio\n",
    "\n",
    "        integrals_old = '\\t\\t'.join(['{:.1e}'.format(x) for x in integrals_old])\n",
    "        integrals_new = '\\t\\t'.join(['{:.1e}'.format(x) for x in integrals_new])\n",
    "        ratio         = '\\t\\t'.join(['{:.1e}'.format(x) for x in ratio        ])\n",
    "\n",
    "        print('Integral {} = {}'.format(i,integrals_old))\n",
    "        print('           = {}'.format(integrals_new))\n",
    "        print('Ratios     = {}'.format(ratio))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.set_image_data_format('channels_last')\n",
    "model_name = 'resnet'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'resnet'\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.05\n",
    "min_delta = 0.001\n",
    "patience = 20 # large patience since loss sometimes fluctuates upwards for a bit?\n",
    "input_shape = (128,16)\n",
    "channels = 6\n",
    "augmentation=True\n",
    "normalization = True\n",
    "filter_sets = [\n",
    "    [64,64,256],\n",
    "    [128,128,512]\n",
    "    #[256,256,1024],\n",
    "    #[512,512,2048]\n",
    "]         \n",
    "f_vals = [3,3] # [3,3,3,3] sizes of filters in middle of conv/identity blocks\n",
    "s_vals = [1,2] # [1,2,2,2] strides for each convolutional block\n",
    "i_vals = [2,3] # [2,3,5,2] number of identity blocks per stage\n",
    "\n",
    "nepochs = 200\n",
    "batch_size = 50 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = model = resnet(\n",
    "    filter_sets=filter_sets, \n",
    "    lr=lr, \n",
    "    channels=channels, \n",
    "    f_vals=f_vals, \n",
    "    s_vals=s_vals, \n",
    "    i_vals=i_vals, \n",
    "    input_shape=input_shape, \n",
    "    augmentation=augmentation,\n",
    "    normalization=normalization\n",
    ")\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = rn_data['train'], \n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = rn_data['valid'], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    rn_data['test'],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(pcells_merged_unflattened)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys=['resnet'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_resnet',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys=['LC EMProb', 'flat_EMB1', 'resnet']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination Network: Take 3\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>\n",
    "For fun, we can also train a combination network where we use our flat DNN's, and ResNet as an additional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_stack = np.column_stack( [model_scores['flat_{}'.format(layer)] for layer in layers])\n",
    "model_scores_stack = np.column_stack((model_scores_stack, model_scores['resnet']))\n",
    "n_input = model_scores_stack.shape[1]\n",
    "\n",
    "nepochs = 50\n",
    "batch_size = 200*ngpu\n",
    "verbose = 2\n",
    "\n",
    "\n",
    "model_name = 'simple_resnet'\n",
    "model_dir = modelpath + model_name # directory for loading/saving ResNet\n",
    "model_key = 'simpleCombine_resnet'\n",
    "\n",
    "lr = 1e-3\n",
    "gamma = 0.1\n",
    "min_delta = 0.001\n",
    "patience = 5\n",
    "\n",
    "nepochs = 100\n",
    "batch_size = 200 * ngpu\n",
    "verbose = 1 # 2 for a lot of printouts\n",
    "    \n",
    "modelfile = '{}/{}{}'.format(model_dir,model_key, file_extension)\n",
    "models[model_key] = simple_combine_model(strategy, lr=lr, n_input=n_input)\n",
    "    \n",
    "# train the network\n",
    "models[model_key], model_history[model_key] = ctu.TrainNetwork(\n",
    "    model=models[model_key], \n",
    "    modelfile=modelfile, \n",
    "    x_train = model_scores_stack[pdata_merged.train],\n",
    "    y_train = plabels[pdata_merged.train], \n",
    "    x_valid = model_scores_stack[pdata_merged.val], \n",
    "    y_valid = plabels[pdata_merged.val], \n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "    epochs=nepochs, \n",
    "    batch_size=batch_size, \n",
    "    verbose=verbose, \n",
    "    overwriteModel=overwriteModel,\n",
    "    finishTraining=finishTraining\n",
    ")\n",
    "        \n",
    "# get performance metric from test set\n",
    "model_performance[model_key] = models[model_key].evaluate(\n",
    "    model_scores_stack[pdata_merged.test],\n",
    "    plabels[pdata_merged.test],\n",
    "    verbose=0\n",
    ")\n",
    "    \n",
    "# get/recalculate network scores for the dataset\n",
    "model_scores[model_key] = models[model_key].predict(model_scores_stack)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.MetricPlot(\n",
    "    model_history,\n",
    "    plotpath=plotpath,\n",
    "    model_keys = ['simpleCombine_resnet'],\n",
    "    plotstyle=plotstyle\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_simple_resnet',\n",
    "    drawPlots=drawPlots,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = ['LC EMProb', 'simpleCombine', 'resnet', 'simpleCombine_cnn', 'simpleCombine_resnet']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Plots\n",
    "<div style=\"text-align: right\"> <a href=\"#Quick-Navigation:\">Top</a> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've trained networks to our hearts' content, we can make a set of ROC curves to summarize our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_keys_default = ['LC EMProb','flat_EMB1', 'simpleCombine', 'cnn_EMB_all', 'cnn_all', 'cnn_merged', 'cnn_split_EMB', 'resnet']\n",
    "draw_cols_default = [plotstyle.colors[(i) % (len(plotstyle.colors)-1)] for i in range(len(draw_keys_default))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_summary',\n",
    "    drawPlots=True,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = ['LC EMProb', 'flat_EMB1', 'flat_EMB2', 'flat_EMB3', 'cnn_EMB1', 'cnn_EMB2', 'cnn_EMB3', 'simpleCombine', 'simpleCombine_cnn', 'cnn_EMB_all', 'cnn_all', 'cnn_merged', 'cnn_split_EMB', 'resnet', 'simpleCombine_resnet']\n",
    ")\n",
    "\n",
    "cpu.RocCurves(\n",
    "    model_scores,\n",
    "    data_labels=plabels[:,1],\n",
    "    indices=pdata_merged.test, \n",
    "    roc_fpr=roc_fpr, \n",
    "    roc_tpr=roc_tpr, \n",
    "    roc_thresh=roc_thresh, \n",
    "    roc_auc=roc_auc, \n",
    "    plotpath=plotpath,\n",
    "    plotname='ROC_best',\n",
    "    drawPlots=True,\n",
    "    plotstyle=plotstyle,\n",
    "    figsize=(30,10),\n",
    "    model_keys = draw_keys_default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make a scatterplot of number of learnable parameters versus accuracy. The number of parameters can be thought of as a stand-in for complexity (though I assume that computational complexity/cost will also depend on the exact operations being performed).\n",
    "\n",
    "Note that there is some inherent hard-coding being done here, since some of our models (e.g. `simpleCombine`) use other models as input -- and for such models, we want to count their inputs' weights plus their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "complexity_scatter = {}\n",
    "\n",
    "for key, model in models.items():\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    accuracy        = model_performance[key][1]\n",
    "    auc             = roc_auc[key]\n",
    "    complexity_scatter[key] = [trainable_count, accuracy, auc]\n",
    "    \n",
    "# manually adjust complexity_scatter for our combination networks\n",
    "flat_weights = np.sum([np.sum([K.count_params(w) for w in models[key].trainable_weights]) for key in ['flat_{}'.format(layer) for layer in layers]])\n",
    "cnn_weights = np.sum([np.sum([K.count_params(w) for w in models[key].trainable_weights]) for key in ['cnn_{}'.format(layer) for layer in layers]])\n",
    "complexity_scatter['simpleCombine'][0] += flat_weights\n",
    "complexity_scatter['simpleCombine_cnn'][0] += cnn_weights\n",
    "complexity_scatter['simpleCombine_resnet'][0] += flat_weights + complexity_scatter['resnet'][0]\n",
    "    \n",
    "fig, ax = plt.subplots(1,2, figsize=(25,10))\n",
    "for axis in ax: plotstyle.SetStylePlt(axis)\n",
    "\n",
    "# Make a scatter -- there will be a lot of points, so consider not drawing them for each network.\n",
    "draw_keys = draw_keys_default[1:]\n",
    "draw_cols = draw_cols_default[1:]\n",
    "\n",
    "for i,key in enumerate(draw_keys):\n",
    "    if(key not in complexity_scatter.keys()): continue\n",
    "    x,y1,y2 = complexity_scatter[key]\n",
    "    ax[0].scatter(x=x,y=y1, label=key, color=draw_cols[i], s=64)\n",
    "    ax[1].scatter(x=x,y=y2, label=key, color=draw_cols[i], s=64)\n",
    "    \n",
    "    ax[0].set_xlabel('# Learnable Parameters')\n",
    "    ax[1].set_xlabel('# Learnable Parameters')\n",
    "    \n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].set_ylabel('Area under ROC curve')\n",
    "    \n",
    "    ax[0].set_xlim([0.,2.5e6])\n",
    "    ax[1].set_xlim([0.,2.5e6])\n",
    "    \n",
    "    ax[0].set_ylim([0.88,1.0])\n",
    "    ax[1].set_ylim([0.95,1.0])\n",
    "\n",
    "legs = []\n",
    "for i,axis in enumerate(ax):\n",
    "    legs.append(axis.legend(facecolor=plotstyle.canv_plt))\n",
    "    for leg_text in legs[-1].get_texts(): leg_text.set_color(plotstyle.text_plt)\n",
    "        \n",
    "qu.SaveSubplots(fig, ax, ['acc_params', 'auc_params'], savedir=plotpath, ps=plotstyle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, `cnn_all` looks like a relatively appealing option -- it's one of the highest-performing networks, and it actually has the fewest learnable parameters. `resnet` performs slightly better, but at the cost of many more learnable weights. This added complexity may translate to slower deployment time, and cause issues if we try to use this network in a triggering context (i.e. on an FPGA), where we will have to deal with significant hardware and timing constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to also make a table (or plot) depicting the false positive rate at different true positive rate (i.e. pick out a few reference points from the ROC curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_data = {}\n",
    "tpr_vals = np.array([0.6,0.8,0.9,0.95])\n",
    "\n",
    "for tpr_val in tpr_vals: \n",
    "    fpr_data[tpr_val] = {}\n",
    "    for i, key in enumerate(roc_fpr.keys()):\n",
    "        \n",
    "        # Want to find the fpr at the given tpr\n",
    "        fpr = roc_fpr[key]\n",
    "        tpr = roc_tpr[key]\n",
    "        f = interp1d(tpr, fpr)        \n",
    "        fpr_data[tpr_val][key] = f(tpr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_keys = draw_keys_default\n",
    "draw_cols = draw_cols_default\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "plotstyle.SetStylePlt(ax)\n",
    "\n",
    "# multiple bars -- handle visual offsets\n",
    "bar_width = 0.2\n",
    "n = len(draw_keys)\n",
    "k = len(fpr_data.keys())\n",
    "offsets = np.linspace(0., (k-1) * bar_width, k)\n",
    "offsets = offsets - np.mean(offsets)\n",
    "\n",
    "# hatches for distinguishing between different tpr values\n",
    "hatches = ['/','\\\\','//','\\\\\\\\']\n",
    "\n",
    "x = np.arange(n)\n",
    "rects = []\n",
    "for i,tpr_val in enumerate(fpr_data.keys()):\n",
    "    vals = [fpr_data[tpr_val][a] for a in draw_keys]\n",
    "    bar = ax.bar(\n",
    "        x + offsets[i], \n",
    "        vals,\n",
    "        bar_width,\n",
    "        label='@ True positive rate = {:.2f}'.format(tpr_val), \n",
    "        color=draw_cols,\n",
    "        hatch = hatches[i],\n",
    "        edgecolor=plotstyle.canv_plt\n",
    "    )\n",
    "    \n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height),\n",
    "            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "            xytext=(-1, 3),  # 1 point horizontal offset, 3 points vertical offset\n",
    "            textcoords=\"offset points\",\n",
    "            color=plotstyle.text_plt,\n",
    "            ha='center', va='bottom'\n",
    "                   )\n",
    "    rects.append(bar)\n",
    "\n",
    "result = ax.set_xticks(x)\n",
    "x_labels = [x.replace('_','\\n') for x in draw_keys]\n",
    "result = ax.set_xticklabels(x_labels)\n",
    "\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('False positive rate')\n",
    "ax.set_ylim(0.,0.4)\n",
    "\n",
    "leg = ax.legend(facecolor=plotstyle.canv_plt)\n",
    "for leg_text in leg.get_texts(): leg_text.set_color(plotstyle.text_plt)\n",
    "    \n",
    "qu.SaveSubplots(fig, np.array([ax]), ['fpr'], savedir=plotpath, ps=plotstyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_keys = ['LC EMProb'] + ['flat_{}'.format(x) for x in layers] + ['cnn_{}'.format(x) for x in layers]\n",
    "draw_cols = [plotstyle.colors[(i) % (len(plotstyle.colors)-1)] for i in range(len(draw_keys))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plotstyle.SetStylePlt(ax)\n",
    "\n",
    "# multiple bars -- handle visual offsets\n",
    "bar_width = 0.2\n",
    "n = len(draw_keys)\n",
    "k = len(fpr_data.keys())\n",
    "offsets = np.linspace(0., (k-1) * bar_width, k)\n",
    "offsets = offsets - np.mean(offsets)\n",
    "\n",
    "# hatches for distinguishing between different tpr values\n",
    "hatches = ['/','\\\\','//','\\\\\\\\']\n",
    "\n",
    "x = np.arange(n)\n",
    "rects = []\n",
    "for i,tpr_val in enumerate(fpr_data.keys()):\n",
    "    vals = [fpr_data[tpr_val][a] for a in draw_keys]\n",
    "    bar = ax.bar(\n",
    "        x + offsets[i], \n",
    "        vals,\n",
    "        bar_width,\n",
    "        label='@ True positive rate = {:.2f}'.format(tpr_val), \n",
    "        color=draw_cols,\n",
    "        hatch = hatches[i],\n",
    "        edgecolor=plotstyle.canv_plt\n",
    "    )\n",
    "    \n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height),\n",
    "            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "            xytext=(-1, 3),  # 1 point horizontal offset, 3 points vertical offset\n",
    "            textcoords=\"offset points\",\n",
    "            color=plotstyle.text_plt,\n",
    "            ha='center', va='bottom'\n",
    "                   )\n",
    "    rects.append(bar)\n",
    "\n",
    "result = ax.set_xticks(x)\n",
    "x_labels = [x.replace('_','\\n') for x in draw_keys]\n",
    "result = ax.set_xticklabels(x_labels)\n",
    "\n",
    "ax.set_xlabel('Method')\n",
    "ax.set_ylabel('False positive rate')\n",
    "ax.set_ylim(0.,1.0)\n",
    "\n",
    "leg = ax.legend(facecolor=plotstyle.canv_plt)\n",
    "for leg_text in leg.get_texts(): leg_text.set_color(plotstyle.text_plt)\n",
    "    \n",
    "qu.SaveSubplots(fig, np.array([ax]), ['fpr_single'], savedir=plotpath, ps=plotstyle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
