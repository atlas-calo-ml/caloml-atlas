{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a32f7a-2841-4ecc-b558-fb273993d596",
   "metadata": {},
   "source": [
    "## Data access demo\n",
    "\n",
    "In this demo, we will take a look at the different options we have for accessing our ML training/testing data. We have two different methods:\n",
    "\n",
    "- Read all the data into memory -- a `pandas.DataFrame` for the scalar-type branches (i.e. 1 value per topo-cluster), and a dictionary of `numpy` arrays for the calorimeter images. This will *also* create HDF5 files holding these data objects, for faster access in the future (i.e. so we don't have to create these from the `ROOT` files again). These objects will be loaded into memory, which means that data access will be fast but we could run into memory issues if using a lot of data.\n",
    "- Stream the data from the `ROOT` files, using a custom `tensorflow.Dataset` class. This will be notably slower than reading everything into memory at once, but will scale well as we can deal with very large datasets.\n",
    "\n",
    "In this demo, we will use both methods to train a simple classifier. Doing this, we'll also see some examples of using our topo-cluster classification networks & network training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba05ca5-bde9-447f-9150-ace061445f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 18:41:56.958880: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n"
     ]
    }
   ],
   "source": [
    "import sys,os,glob,time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uproot as ur\n",
    "import ROOT as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a6087f-c331-4d1a-9e84-feeba42ee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom stuff.\n",
    "path_prefix = os.getcwd() + '/../'\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util as pu\n",
    "from util import ml_util as mu\n",
    "from util import qol_util as qu\n",
    "from util import data_util as du\n",
    "\n",
    "# Some more custom stuff (tf.keras things).\n",
    "from util.keras.callbacks import GetCallbacks\n",
    "\n",
    "# Some more custom stuff (classification-specific).\n",
    "from util.classification import data_util as cdu\n",
    "from util.classification import training_util as ctu\n",
    "from util.classification.models import baseline_nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57452e-9be0-47ff-849c-7fc1bf0cfa84",
   "metadata": {},
   "source": [
    "Let's fetch our data. Note that the paths here are specific to however you have stored the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd31b139-848c-4e15-ace6-eee30d49a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath=path_prefix+'data/pion/'\n",
    "rootfiles = {        \n",
    "    'p0':inputpath + 'user.mswiatlo.900246.PG_singlepi0_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root',\n",
    "    'pp':inputpath + 'user.mswiatlo.900247.PG_singlepion_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root'\n",
    "}\n",
    "\n",
    "# Let's explicitly list the root files for each category, so that we can trim down the lists (makes this run faster!).\n",
    "# Our methods below can use either the glob-compatible strings above, or the lists we're making.\n",
    "nfiles = 3\n",
    "rootfiles = {key:glob.glob(val,recursive=True)[:nfiles] for key,val in rootfiles.items()}\n",
    "\n",
    "# Names for our scalar-type branches (cluster energy, eta, etc.). \n",
    "# We are not actually using them in this demo, besides a trivial clusterEta cut, but just demonstrating how one would access these.\n",
    "branches = [\n",
    "            'cluster_ENG_CALIB_TOT','clusterEta'\n",
    "]\n",
    "\n",
    "layers = ['EMB1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154729b1-1636-41ab-b0cb-a8cb6f1e6885",
   "metadata": {},
   "source": [
    "Let's define our network architecture -- it will be used in both parts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4187376-1ffe-4597-bcf4-0f223aeee8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-4\n",
    "nepochs = 3\n",
    "patience = 2\n",
    "batch_size = 600 # relatively large batch size -- but this makes sure things run rather quickly for the demo (esp. relevant when streaming).\n",
    "gamma = 0.1\n",
    "min_delta = 0.0001\n",
    "dropout = 0.1\n",
    "normalization = True\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a812de-62cb-4d4c-9e6f-219554a93889",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'EMB1'\n",
    "assert(layer in layers)\n",
    "npix = mu.cell_meta[layer]['len_eta'] * mu.cell_meta[layer]['len_phi']\n",
    "architecture = baseline_nn_model(None, npix, lr=lr, dropout=dropout, normalization=normalization,input_name=layer) # TODO: strategy is unused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7730edd-c876-4bc9-9d76-cd4af8dbd5ae",
   "metadata": {},
   "source": [
    "## Part 1: In-memory data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558115a-29dc-4289-b312-21948c3bdbbe",
   "metadata": {},
   "source": [
    "Now let's load the data into memory, using the `pandas` + `numpy` approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c34750-7571-42d9-8a8f-d06a76794b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_name_suffix = 'data_demo'\n",
    "h5_name = inputpath + h5_name_suffix\n",
    "modelfile = 'demo_network_memory.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad470ed-4b9d-499c-9679-d8a99057a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = [\n",
    "#    ['cluster_ENG_CALIB_TOT',.2,'lower'], # Note: I've commented this out since our data-streaming method (part 2) can't do cuts yet, and we want an apples-to-apples comparison to the extent possible.\n",
    "    ['clusterEta',(-0.7,0.7),'window'] # This is actually a redundant cut -- already present in our data, but it demonstrates how one applies one.\n",
    "]\n",
    "\n",
    "cut_distributions = [x[0] for x in cuts]\n",
    "cut_values = [x[1] for x in cuts]\n",
    "cut_types = [x[2] for x in cuts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ba363-b029-4300-9a0e-5383fb8b5909",
   "metadata": {},
   "source": [
    "The `ml_util.setupPionData()` function handles our data preparation -- for those familiar with previous methods (e.g. those used in Max's Jupyter notebooks), this is quite similar but a bunch of things are handled under-the-hood. In the example below, `pdata` will be a `pandas.DataFrame` with our scalar-type branches, and `pcells` will be a dictionary of `numpy` arrays representing the calorimeter images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ef3ddb-80fe-420f-830c-bb3cdd850444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying cut on distribution: clusterEta.\n",
      "Matching data series on distribution: cluster_ENG_CALIB_TOT.\n",
      "Balancing data: 81821 events per category.\n",
      "Preparing pandas DataFrame.\n",
      "Preparing calorimeter images. |\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m| 100.0% % Complete\n"
     ]
    }
   ],
   "source": [
    "pdata,pcells = mu.setupPionData(\n",
    "    rootfiles, \n",
    "    branches=branches, \n",
    "    layers=layers, \n",
    "    balance_data=True, # Whether or not to make sure to have equal numbers of pi0 and pi+ events\n",
    "    n_max = -1, # take this many events (or max possible) from pi0 and pi+. Set to -1 to take the max possible w/out upper cap. Not relevant if not balancing the data.\n",
    "    verbose=True,\n",
    "    load=False, # if True, will load files w/ requested names if they exist\n",
    "    save=False, # if True, saves some HDF5 files\n",
    "    filename=h5_name,\n",
    "    match_distribution='cluster_ENG_CALIB_TOT', # balance the data by matching this distribution ffor pi0 and pi+\n",
    "    match_binning = (20000,0.,2000.), # binning for doing the matching\n",
    "    cut_distributions=cut_distributions, # cut on these distributions\n",
    "    cut_values=cut_values, # defines the cuts for the above distributions (single value for upper/lower, tuple for window)\n",
    "    cut_types=cut_types # defines the cut type for the above distributions (lower, upper or window)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef37117-962b-42a2-956f-766748263506",
   "metadata": {},
   "source": [
    "Now let's define our indices for training, validation and testing. Note that we accomplish this with a function from the `util.classification` sub-library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6daecdf3-db3c-414d-bb7a-2eec39a77b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata_merged, pcells_merged, plabels = cdu.DataPrep(pdata, \n",
    "                                                    pcells, \n",
    "                                                    layers, \n",
    "                                                    trainfrac=0.7,\n",
    "                                                    filename='' # if not blank, will save an HDF5 file containing indices\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6629e03b-a29f-4e2d-99d2-39043d0121cb",
   "metadata": {},
   "source": [
    "Now let's train a simple DNN using our data (it will only use the `EMB1` layer from our calorimeter images)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456fd64-c219-478e-a616-6fc6a4bbf2b1",
   "metadata": {},
   "source": [
    "The `util.classification.TrainNetwork()` function below will train/load our neural network. It returns the trained model, as well as a \"history\" object containing metrics like network accuracy and ROC curve AUC as a function of epoch. The trained model will be saved to an HDF5 file, and the history will be saved to a CSV file, both using the `modelfile` parameter to determine the filename.\n",
    "\n",
    "The callbacks that are provided by our `GetCallbacks()` function includes a learning rate scheduler (which causes the learning rate to undergo exponential decay from one epoch to the next), as well as an early stopping condition that will stop training if the validation loss does not improve after a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3501bc-15b5-4e07-8a43-e115511213dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "191/191 [==============================] - 2s 7ms/step - loss: 0.6001 - acc: 0.6982 - val_loss: 0.5264 - val_acc: 0.7641\n",
      "Epoch 2/3\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.5063 - acc: 0.7791 - val_loss: 0.4881 - val_acc: 0.7908\n",
      "Epoch 3/3\n",
      "191/191 [==============================] - 1s 5ms/step - loss: 0.4853 - acc: 0.7928 - val_loss: 0.4729 - val_acc: 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 18:42:13.740329: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-11 18:42:13.794628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro P5000 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 269.00GiB/s\n",
      "2021-10-11 18:42:13.794662: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-11 18:42:13.797774: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-11 18:42:13.797867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-11 18:42:13.798680: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-11 18:42:13.798957: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-11 18:42:13.799921: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-11 18:42:13.800614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-11 18:42:13.800807: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-11 18:42:13.802030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-11 18:42:13.804212: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-11 18:42:13.809672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro P5000 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 269.00GiB/s\n",
      "2021-10-11 18:42:13.813329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-10-11 18:42:13.813440: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-11 18:42:14.351179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-11 18:42:14.351215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-11 18:42:14.351222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-11 18:42:14.353068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15549 MB memory) -> physical GPU (device: 0, name: Quadro P5000, pci bus id: 0000:18:00.0, compute capability: 6.1)\n",
      "2021-10-11 18:42:14.952180: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-11 18:42:14.972553: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "2021-10-11 18:42:15.431175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-11 18:42:15.771726: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    }
   ],
   "source": [
    "start_time_1 = time.time()\n",
    "\n",
    "model,history = ctu.TrainNetwork(\n",
    "    model=architecture,\n",
    "    modelfile=modelfile,\n",
    "    x_train = pcells_merged[layer][pdata_merged.train],\n",
    "    y_train = plabels[pdata_merged.train],\n",
    "    x_valid = pcells_merged[layer][pdata_merged.val],\n",
    "    y_valid = plabels[pdata_merged.val],\n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience),\n",
    "    epochs=nepochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    "    overwriteModel=True, # whether or not to overwrite an existing file (modelfile) -- if not, load that file's network\n",
    "    finishTraining=False # if loading a model, try to train to last requested epoch if training had ended early (e.g. due to patience parameter)\n",
    ")\n",
    "\n",
    "end_time_1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbe8ce-b05c-4822-b68c-5faaa08bb675",
   "metadata": {},
   "source": [
    "## Part 2: Using file streaming\n",
    "\n",
    "Now let's do the same thing as above, but using our data streaming instead of loading the data into memory. A few notes and caveats:\n",
    "\n",
    "- You might have noticed that our `util.ml_util.SetupPionData()` function took a *dictionary* of `ROOT` files, where the keys represented the different categories (e.g. signal vs. background) and the values were lists of `ROOT` files. Our `MLV1Dataset` can take either such a dictionary of `ROOT` files or a list of `ROOT` files. If using a dictionary, the keys will once again represent different categories. If using a list, one must also supply a `target` argument, which is the name of a branch in the `ROOT` files' trees -- this can be used for regression, for example measuring the calibration hits of topo-clusters.\n",
    "- Using a larger batch size will increase memory consumption, but notably speed things up as well -- thus there is some balance to strike.\n",
    "- You can specify a `step_size`, which determines the size of the buffer used for reading the files. The larger the buffer, the faster the reading should be -- but this will increase memory usage. If not specified, the `step_size` will default to as many megabytes as there are elements in a single batch (e.g. if the batch size is 200, then `step_size` will default to `\"200 MB\"`).\n",
    "- As with our other data method, we can specify which branches we wish to use, here via the `scalar_branches` and `matrix_branches` arguments. I think that it is good practice to only select the branches you really need, as this may speed things up.\n",
    "- We don't yet have any way of performing pre-selection cuts on the data -- so the `ROOT` files being used should have any cuts already applied (by contrast, we performed some cuts in Part 1). We may later add this functionality. Similarly, we do not have a way of \"balancing\" the data (matching signal and background on some distribution). For the time being, one may accomplish these things via some separate pre-processing of the `ROOT` files, but in the long-term I would like to build it into this data streaming class for ease-of-use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97593471-db4b-4dd6-bc1e-c302c52f9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'demo_network_streaming.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce1e3221-0308-4605-8605-b2e524592b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: target is set to cluster_ENG_CALIB_TOT, but ROOT files have been passed as a dictionary -> target will be ignored, using dictionary keys as classification labels.\n"
     ]
    }
   ],
   "source": [
    "data_stream = du.MLTreeV1Dataset(\n",
    "    root_files = rootfiles,\n",
    "    tree_name = 'ClusterTree',\n",
    "    scalar_branches = branches,\n",
    "    matrix_branches = ['EMB1'], # Note: the default argument is the full list fetched via ml_util.cell_meta.keys()\n",
    "    target = 'cluster_ENG_CALIB_TOT', # Note: For classification we aren't actually using this target -- it will print a warning letting us know.\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    step_size = None,\n",
    "    prefetch = True,\n",
    "    flatten_images = True # whether or not to flatten the image branches\n",
    "    #key_map = {'EMB1':'input'} # remap the EMB1 Tensor to a Tensor named \"input\" (which is what the network expects the input tensor to be named)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67683e4e-597f-4f64-b026-9cccea5ac7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/jano/miniconda3/envs/ml4p/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:588: UserWarning: Input dict contained keys ['clusterEta'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 152s 242ms/step - loss: 0.4382 - acc: 0.8151 - val_loss: 0.3715 - val_acc: 0.8555\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.3600 - acc: 0.8585 - val_loss: 0.3391 - val_acc: 0.8679\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 150s 240ms/step - loss: 0.3396 - acc: 0.8685 - val_loss: 0.3270 - val_acc: 0.8724\n"
     ]
    }
   ],
   "source": [
    "start_time_2 = time.time()\n",
    "\n",
    "model,history = ctu.TrainNetwork(\n",
    "    model=architecture,\n",
    "    modelfile=modelfile,\n",
    "    data_train = data_stream,\n",
    "    data_valid = data_stream,\n",
    "    callbacks = GetCallbacks(modelfile, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience),\n",
    "    epochs=nepochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=verbose,\n",
    "    overwriteModel=True, # whether or not to overwrite an existing file (modelfile) -- if not, load that file's network\n",
    "    finishTraining=False # if loading a model, try to train to last requested epoch if training had ended early (e.g. due to patience parameter)\n",
    ")\n",
    "\n",
    "end_time_2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a53322-3ec0-48f8-a4d4-4bdc7dbeeb27",
   "metadata": {},
   "source": [
    "Given the lack of \"data balancing\" for our streaming method, we can only make a limited comparison between the network results (ideally they would be identical, but the training conditions differ for now). If our full dataset has more signal than background or vice-versa, interpreting the accuracy printed above is not so simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50843483-776c-4b31-a9da-abf7e0aa5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time for in-memory data: 5.481272459030151s\n",
      "Total training time for steaming data:  452.71575379371643s\n"
     ]
    }
   ],
   "source": [
    "dt_1 = end_time_1 - start_time_1\n",
    "dt_2 = end_time_2 - start_time_2\n",
    "\n",
    "print('Total training time for in-memory data: {}s'.format(dt_1))\n",
    "print('Total training time for steaming data:  {}s'.format(dt_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb29102-f0db-43d7-b86a-fe7d85d2cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Quick test: Plot integrals of images, make sure things look OK --\n",
    "\n",
    "# n = 50\n",
    "# data_stream_mini = data_stream.take(n)\n",
    "\n",
    "# n = len(data_stream_mini)\n",
    "# sums = np.zeros(n)\n",
    "# for i,x in enumerate(data_stream_mini):\n",
    "#     sums[i] = np.sum(x[0]['EMB1'].numpy())\n",
    "    \n",
    "# rt.gStyle.SetOptStat(1)\n",
    "# c = rt.TCanvas(qu.RN(),'',800,600)\n",
    "# h = rt.TH1F(qu.RN(),'',1000,0.,100.)\n",
    "\n",
    "# for s in sums: h.Fill(s)\n",
    "# h.Draw()\n",
    "# c.Draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
