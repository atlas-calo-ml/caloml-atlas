{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ba84a4-103e-40c7-bc95-b77409f8eace",
   "metadata": {},
   "source": [
    "# ML4P for Jet Clustering\n",
    "\n",
    "In this notebook, we'll use our topo-cluster classifiers and regressors to correct the energies of topo-clusters, and then cluster these topo-clusters into jets! The goal is to see how using these corrected energies (i.e. applying our ML stuff) affects the jet energy scale resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821fa6a-3184-4d7b-a52a-b6b7c05a077e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we have to import a whole bunch of things we'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd47694-4bb6-41ad-b6e1-cf5d19ef5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 08:29:04.654929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# First, the generic imports.\n",
    "import sys, os, glob, uuid, pathlib\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import pandas as pd\n",
    "import ROOT as rt # Mostly useful here for plotting\n",
    "import matplotlib.pyplot as plt # Alternative plotting option\n",
    "import uproot as ur\n",
    "import awkward as ak\n",
    "\n",
    "# Next, import our utilities. We define our \"path_prefix\" from where we can find them.\n",
    "path_prefix = os.getcwd() + '/../'\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "\n",
    "from util import ml_util as mu # Data preparation and wrangling for our neural networks.\n",
    "from util import qol_util as qu # Quality-of-life stuff, like plot styles and progress bars.\n",
    "from util import jet_util as ju # Jet-specific utilities, e.g. wrapping for FastJet & introducing our ML outputs to jet clustering.\n",
    "from util import io_util as iu # Utilities for scaling regression input/output.\n",
    "\n",
    "# Classification-specific utilities (network setup).\n",
    "from util.classification import data_util as cdu\n",
    "from util.classification import training_util as ctu # besides training, can be used to load network from file\n",
    "import util.classification.models as classifier_models\n",
    "import util.classification.models_exp as classifier_models_exp\n",
    "\n",
    "# Regression-specific utilities (data-loading, network setup).\n",
    "from util.regression import data_util as rdu\n",
    "from util.regression import training_util as rtu # besides training, can be used to load network from file\n",
    "import util.regression.models as regressor_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cacf7450-7808-4697-9921-f5c4b0732734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some plotting stuff.\n",
    "plot_style = 'dark'\n",
    "ps = qu.PlotStyle(plot_style)\n",
    "ps.SetStyle() # will automatically affect ROOT plots from here on out, it sets ROOT.gStyle.\n",
    "rt.gStyle.SetOptStat(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3019f74c-97ed-4295-ad87-5eb7f231673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some calorimeter metadata.\n",
    "# TODO: Get this from one of our libraries\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "cell_shapes = {layers[i]:(len_eta[i],len_phi[i]) for i in range(len(layers))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f175383-4730-40c8-9b71-131a01362c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform fastjet setup. This function will download & build fastjet if it isn't found at the given location.\n",
    "fastjet_dir = path_prefix + 'fastjet'\n",
    "fastjet_dir =  ju.BuildFastjet(fastjet_dir, j=8)\n",
    "fastjet_dir = glob.glob('{}/**/site-packages'.format(fastjet_dir),recursive=True)[0]\n",
    "if(fastjet_dir not in sys.path): sys.path.append(fastjet_dir)\n",
    "import fastjet as fj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd199e2-b9d9-419e-9a6a-4a60d1998d1c",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Let's also fetch our jet data. This is MC dijet data, so we have some light-quark jets to work with. The data contains information on topo-clusters for each event -- the same cell-level and cluster-level info we have with our network training data.\n",
    "\n",
    "We *also* need to fetch the locations of our classification and energy regression networks, so that we can load and apply them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4302c52a-347a-4f0c-a474-b5d992735aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_name_suffix = 'jdata' # used for HDF5 files containing selected events\n",
    "\n",
    "# We package things as a dictionary for now, since that's what our `setupPionData` function expects.\n",
    "data_dir = path_prefix + 'data/jet_small'\n",
    "rootfiles = {'jet':glob.glob(data_dir + '/*.root')}\n",
    "branches = [\n",
    "            'clusterE', 'clusterECalib', \n",
    "            'clusterPt', 'clusterEta', 'clusterPhi', \n",
    "            'cluster_nCells', 'cluster_sumCellE', \n",
    "            'cluster_ENG_CALIB_TOT', 'cluster_EM_PROBABILITY'\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c73c1d8-31fb-4698-8929-ec5a1fe5c029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pandas DataFrame and calo images from /local/home/jano/ml4pions/LCStudies/jets/../data/jet_small/jdata_frame.h5 and /local/home/jano/ml4pions/LCStudies/jets/../data/jet_small/jdata_images.h5.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "h5_name = '/'.join((data_dir,h5_name_suffix))\n",
    "\n",
    "pdata,pcells = mu.setupPionData(rootfiles,\n",
    "                                branches=branches,\n",
    "                                layers=layers,\n",
    "                                balance_data=True,\n",
    "                                n_max = 1000,\n",
    "                                verbose=True,\n",
    "                                load=True,\n",
    "                                save=True,\n",
    "                                filename=h5_name,\n",
    "                                cut_distributions=['cluster_ENG_CALIB_TOT','clusterEta'],\n",
    "                                cut_values = [.2, (-0.7,0.7)],\n",
    "                                cut_types=['lower','window']\n",
    "                               )\n",
    "\n",
    "# Get rid of one layers of keys, which is redundant in this case.\n",
    "pdata = pdata['jet']\n",
    "pcells = pcells['jet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90112a92-a39e-4063-b06f-6bdd9f8c3c54",
   "metadata": {},
   "source": [
    "We also want to fetch information on EM and LC jets. These are stored in trees called `EventTree` in our files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57f7f83-bc9d-4fa2-9e4d-3d7093212fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_branches = [\n",
    "    'AntiKt4EMTopoJetsPt',\n",
    "    'AntiKt4EMTopoJetsEta',\n",
    "    'AntiKt4EMTopoJetsPhi',\n",
    "    'AntiKt4EMTopoJetsE',\n",
    "    'AntiKt4LCTopoJetsPt',\n",
    "    'AntiKt4LCTopoJetsEta',\n",
    "    'AntiKt4LCTopoJetsPhi',\n",
    "    'AntiKt4LCTopoJetsE'\n",
    "]\n",
    "\n",
    "jet_info = ur.lazy([':'.join((x,'EventTree')) for x in rootfiles['jet']],filter_branch=lambda x: x.name in jet_branches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef6e49-8159-4540-ba77-5632695ae9fc",
   "metadata": {},
   "source": [
    "### Network Preparation\n",
    "\n",
    "Besides loading the jet data, we also need to load our models (neural networks), which we will apply to the data in order to get the corrected topo-cluster energies.\n",
    "\n",
    "We have a number of different classifiers and regressors available -- here we will choose which ones we use. Note that our choice of classifier/regressor may also affect *how* we have to load the data. So if we switch models, we may also have to change our data-loading code.\n",
    "\n",
    "Also note that for the energy regression, we are using a *binned* regression -- thus we will have multiple regressors for both charged and neutral pions, each corresponding to a particular range of topo-cluster reco energies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa7364-dc63-4bc2-84f5-9147742f457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dir = path_prefix + 'classifier/Models/pion3'\n",
    "classifier_modelname = 'cnn_split_EMB'\n",
    "classifier_file = classification_dir + '/cnn/{}.h5'.format(classifier_modelname)\n",
    "classifier_model = classifier_models_exp.exp_merged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edbfb0-d028-4d0c-8c37-83367e02f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dir = path_prefix + 'regression_binned/Models/split_3'\n",
    "regressor_modelname = 'split_emb_cnn'\n",
    "regressor_model = regressor_models.split_emb_cnn\n",
    "\n",
    "reco_energy_bin_edges = [0.,1.,10.] # lower bin edges\n",
    "\n",
    "regression_files = {\n",
    "    'charged': glob.glob(regression_dir + '/*/{a}/{a}_charged.h5'.format(a=regressor_modelname)),\n",
    "    'neutral': glob.glob(regression_dir + '/*/{a}/{a}_neutral.h5'.format(a=regressor_modelname))\n",
    "}\n",
    "\n",
    "scaler_files = glob.glob(regression_dir + '/*/scalers.save')\n",
    "scaler_files.sort()\n",
    "\n",
    "for key,val in regression_files.items():\n",
    "    regression_files[key].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971ce48-e0cd-430e-9e67-3e0bea56ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we explicitly check that the filenames are lined up, i.e. that we will pair up the right scalers with the regression files.\n",
    "for i,scaler_file in enumerate(scaler_files):\n",
    "    bin_name = scaler_file.replace(regression_dir + '/','').split('/')[0]    \n",
    "    for key,val in regression_files.items():\n",
    "        bin_name_2 = val[i].replace(regression_dir + '/','').split('/')[0]\n",
    "        assert(bin_name == bin_name_2)\n",
    "        \n",
    "# Also make sure that we have the right number of reco bin edges\n",
    "for key,val in regression_files.items():\n",
    "    assert(len(val) == len(reco_energy_bin_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03967b33-c6af-47ac-b98c-e0da8cd1aabe",
   "metadata": {},
   "source": [
    "Now we must define our regression variables -- our energy regression will need some inputs that undergo some scaling, which is some mapping (a function) followed by application of some scalers (which were derived using training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747c675-9a24-493c-94e7-bc25e75896e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1.\n",
    "b = 1.0e-5\n",
    "EnergyMapping = iu.LogMapping(b=b,m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638b74d-2076-4bde-9a5f-1cc36c3f08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some regression vars.\n",
    "pdata['logE'] = EnergyMapping.Forward(pdata['clusterE'].to_numpy()) # log of reco energy, possible network input\n",
    "pdata['clusterEtaAbs'] = np.abs(pdata['clusterEta'].to_numpy()) # absolute value of eta, possible network input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a2f2d-75c7-4bb5-9022-3addb6734f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: We have scalers derived from charged pion and neutral pion data. We're just using the charged pion ones -- does this make sense?\n",
    "scalers = []\n",
    "scaler_branches = ['logE', 'clusterEtaAbs']\n",
    "scaled_variable_prefixes = ['s{}'.format(i) for i in range(len(scaler_files))]\n",
    "for i,scaler_file in enumerate(scaler_files):\n",
    "    scalers.append(mu.setupScalers({'pp':pdata}, scaler_branches, scaler_file, scaled_variable_prefixes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f98f3d-466b-4418-82ae-7b0e3c2a5feb",
   "metadata": {},
   "source": [
    "Let's load the actual networks now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3fbc3-325b-4b62-9864-eff5d724feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, _ = ctu.TrainNetwork(classifier_model(), classifier_file, overwriteModel=False, finishTraining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af50c3-dedc-46be-9da1-bdf96889af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = {}\n",
    "\n",
    "for key,val in regression_files.items():\n",
    "    regressor[key] = []\n",
    "    for regressor_file in val:\n",
    "        reg, _ = rtu.TrainNetwork(regressor_model(), regressor_file, overwriteModel=False, finishTraining=False)\n",
    "        regressor[key].append(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50b882-6721-4714-b8fa-5d25a572e2e3",
   "metadata": {},
   "source": [
    "Since we are using multiple regressors binned by reco energy, let's fetch the indices of events that will be passed to each regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33738aa2-6b27-4c59-8dae-0159deb9aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_indices = []\n",
    "\n",
    "for i in range(len(reco_energy_bin_edges)-1,-1,-1):\n",
    "    \n",
    "    indices = pdata['clusterE'].to_numpy() > reco_energy_bin_edges[i]\n",
    "\n",
    "    if(i != len(reco_energy_bin_edges)-1):\n",
    "        indices *= pdata['clusterE'].to_numpy() < reco_energy_bin_edges[i+1]\n",
    "        \n",
    "    indices = np.where(indices)[0]\n",
    "    regressor_indices.append(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa3fb2-994c-4786-86a1-1dd4f9304ed3",
   "metadata": {},
   "source": [
    "Lastly, we package the data in the format that our networks will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f363e1-8c2d-4a05-9390-8db22ed42ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier data.\n",
    "classifier_input = cdu.ReshapeImages(pcells, cell_shapes, use_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc81e1-a860-4cc9-8ec6-59863e9b74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor data. Note that we have a set of data for each of our regression energy bins, as they\n",
    "# use different scaled energies.\n",
    "regressor_input = []\n",
    "for i in range(len(reco_energy_bin_edges)):\n",
    "    prefix = scaled_variable_prefixes[i]\n",
    "    dummy_key = 'jet'\n",
    "    reg_input = rdu.ResnetInput(\n",
    "        {dummy_key:pdata},\n",
    "        {dummy_key:pcells},\n",
    "        branch_map = {\n",
    "            '{}_logE'.format(prefix):'energy',\n",
    "            '{}_clusterEtaAbs'.format(prefix):'eta'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    reg_input = reg_input[dummy_key]\n",
    "    \n",
    "    # We can immediately pare things down by removing clusters that won't be used by a particular regressor.\n",
    "    for key in reg_input.keys():\n",
    "        reg_input[key] = reg_input[key][regressor_indices[i]]\n",
    "    \n",
    "    regressor_input.append(reg_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357742e-0035-493d-818a-e3c2ecaf5a10",
   "metadata": {},
   "source": [
    "## Apply Neural Networks\n",
    "\n",
    "Now that we've loaded our data and prepared our neural networks, we want to evaluate them on the data to get our classification scores and corrected energies.\n",
    "\n",
    "The simplest way to do this would be to evaluate every network on every event. However, it will be more efficient to avoid evaluating regressors on topo-clusters outside their energy range, since we would not use the result anyway.\n",
    "\n",
    "We could also in principle define our classification score cut here -- and only apply charged/neutral regressions to each topo-cluster based on its score and that cut. But it's easier to just apply the charged and neutral regression to each topo-cluster, so that we can adjust the cut afterwards without having to recompute things.\n",
    "\n",
    "Lastly, we will save our network outputs to a file that can be loaded, so that we don't have to re-evaluate the networks every time. We just have to make sure to move/remove this file if we change something about the evaluation, e.g. which models we're using. Ultimately we'll want to design this so that if we're loading the scores from a file, we don't even load the networks into memory as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831649ab-a4a5-40e5-ad1a-36fc97de4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_score_file = 'classification_scores.h5'\n",
    "regression_score_file = 'regression_scores.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c272b9-9579-466f-9157-550e28e564f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the classification scores -- this is the simple part, we just apply the same classifier to all topo-clusters.\n",
    "\n",
    "if(not pathlib.Path(classification_score_file).exists()):\n",
    "    \n",
    "    # Evaluate the network.\n",
    "    print('Evaluating classifier.')\n",
    "    classification_scores = classifier.predict(classifier_input)[:,1]\n",
    "    \n",
    "    # Save these scores to a file.\n",
    "    print('Saving classification scores to {}.'.format(classification_score_file))\n",
    "    hf = h5.File(classification_score_file, 'w')\n",
    "    dset = hf.create_dataset('scores',data=classification_scores,compression='gzip', compression_opts=7)\n",
    "    hf.close()\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Load the scores from a file.\n",
    "    print('Loading classification scores from {}.'.format(classification_score_file))\n",
    "    hf = h5.File(classification_score_file,'r')\n",
    "    classification_scores = hf['scores'][:]\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f065707-bdb2-4d89-b114-7c97cdf151cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now handle the regression scores.\n",
    "regression_scores = {}\n",
    "\n",
    "if(not pathlib.Path(regression_score_file).exists()):\n",
    "    print('Evaluating regressors.')\n",
    "    for key,regressor_set in regressor.items():\n",
    "        scores = np.zeros(len(pdata))\n",
    "        for i,reg in enumerate(regressor_set):\n",
    "            scores[regressor_indices[i]] = rtu.GetPredictions(regressor=reg, model_input=regressor_input[i])\n",
    "        regression_scores[key] = scores\n",
    "    \n",
    "    # Now save the scores to a file.\n",
    "    print('Saving regression scores to {}.'.format(regression_score_file))\n",
    "    hf = h5.File(regression_score_file, 'w')\n",
    "    for key,val in regression_scores.items():\n",
    "        dset = hf.create_dataset(key,data=val ,compression='gzip', compression_opts=7)\n",
    "    hf.close()\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Load the scores from a file.\n",
    "    print('Loading regression scores from {}.'.format(regression_score_file))\n",
    "    hf = h5.File(regression_score_file,'r')\n",
    "    for key in hf.keys():\n",
    "        regression_scores[key] = hf[key][:]\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b55761-f3f1-4a79-8096-54919b2e52f9",
   "metadata": {},
   "source": [
    "Now that we've collected our classification and regressino scores, let's add the relevant data to our `pandas.DataFrame`.\n",
    "\n",
    "Note that we are using regressors that predict the *ratio* between true and reco energy, not the reco energy itself -- so we must multiply the existing reco energy by the regression scores to get the new predicted energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a672d-13a1-4928-88ff-0a24e8ccb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_key = 'score'\n",
    "regression_key_prefix = 'clusterE_pred'\n",
    "regression_keys = {key:regression_key_prefix + '_' + key for key in regression_scores.keys()}\n",
    "\n",
    "pdata[classification_key] = classification_scores\n",
    "\n",
    "for key,val in regression_keys.items():\n",
    "    pdata[val] = regression_scores[key] * pdata['clusterE'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ecca5e-001b-421e-9e75-7875fa70d968",
   "metadata": {},
   "source": [
    "## Plotting network results\n",
    "\n",
    "Before going any further, we can plot some network results -- our classification and regression scores, the corresponding predicted energies for each regression, and the ratio of predicted energy to reco energy for each regression.\n",
    "\n",
    "**TODO:** Note that we have a charged regression result and a neutral regression result for *each* topo-cluster -- in other words there's some double-counting going on, because ultimately we will treat each topo-cluster as only charged or neutral. Without immediately deciding on a classification score cut, we can make a 2D plot showing the distribution of charged or neutral regression scores (or predicted energies) as a function of that cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d902d-2382-42f8-84d6-65367fd0b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = rt.TCanvas(qu.RN(),qu.RN(),1600,600)\n",
    "c.Divide(2,1)\n",
    "\n",
    "# ---\n",
    "c.cd(1)\n",
    "hist = rt.TH1F(qu.RN(),'Classification Scores;Score;Fractional Count',102,-0.01,1.01)\n",
    "for entry in classification_scores: hist.Fill(entry)\n",
    "hist.SetLineColor(ps.main)\n",
    "hist.SetFillColorAlpha(ps.main, 0.5)\n",
    "hist.Scale(1./hist.Integral())\n",
    "hist.Draw('HIST')\n",
    "# ---\n",
    "c.cd(2)\n",
    "stack = rt.THStack(qu.RN(),'Regression Scores;Score;Fractional Count')\n",
    "leg = rt.TLegend(0.75,0.8,0.9,0.9)\n",
    "h = {key:rt.TH1F(qu.RN(),'',100,0.,2.0) for key in regression_scores.keys()}\n",
    "colors = [ps.curve, ps.text]\n",
    "\n",
    "for i,key in enumerate(regression_scores.keys()):\n",
    "    for entry in regression_scores[key]:\n",
    "        h[key].Fill(entry)\n",
    "    h[key].SetLineColor(colors[i])\n",
    "    h[key].SetFillColorAlpha(colors[i],0.1)\n",
    "    h[key].Scale(1./h[key].Integral())\n",
    "    stack.Add(h[key])\n",
    "    leg.AddEntry(h[key],key,'lf')\n",
    "stack.Draw('NOSTACK HIST')\n",
    "leg.SetTextColor(ps.text)\n",
    "leg.Draw()\n",
    "# ---\n",
    "\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec974a-1c6f-4720-84f4-85c9b3df8256",
   "metadata": {},
   "source": [
    "From the simple plots above, things look sensible -- it looks like our topo-clusters are predominantly predicted to be charged pions. And consistent with our results in training, we see that the neutral pion regression doesn't shift the energy very much, whereas the charged regression will typically shift the energy slightly upwards. Of course, these plots include *charged pion* regression scores for clusters likely to be *neutral* pions and vice-versa, but it's nonetheless a sensible result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d427980-9206-439c-a25d-7fbb713e0612",
   "metadata": {},
   "source": [
    "## Defining a classification score cut.\n",
    "\n",
    "At this point, we might want to choose a classification score cut. All topo-clusters with scores below this cut will be treated as neutral pions, and all topo-clusters with scores above this cut will be treated as charged pions.\n",
    "\n",
    "**TODO:** We ultimately might want to define this within our jet-clustering function/routine, so that we can easily see how shifting this cut affects output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34daf5-960a-488a-8443-25df5328e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_score_cut = 0.5\n",
    "predicted_energy_key = 'clusterE_pred'\n",
    "\n",
    "# Funky stuff since I'm not very familiar with pandas tricks.\n",
    "clusterE_pred = np.array(pdata['clusterE_pred_neutral'].to_numpy()) # make a copy\n",
    "charged_idxs = (pdata[classification_key] > classification_score_cut).to_numpy()\n",
    "clusterE_pred[charged_idxs] = pdata['clusterE_pred_charged'][charged_idxs].to_numpy()\n",
    "\n",
    "pdata[predicted_energy_key] = clusterE_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd04ed-1d6b-4d72-ab83-63f685ba1c59",
   "metadata": {},
   "source": [
    "## Jet clustering\n",
    "\n",
    "Now we want to cluster jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d104e4f-193e-46cf-8c1d-bb5b628951a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5600f9-94d9-49d1-b13a-a8277673e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile = glob.glob(rootfiles['jet'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d471c-a157-474e-9393-6051355acd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ur.open(rfile)\n",
    "t = f['EventTree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832eafd9-1c97-439f-979f-1e81e6c34896",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da0ffc-3818-4d30-a57f-5816667d5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13773f6a-ec82-40f6-9f07-c5af6df823af",
   "metadata": {},
   "outputs": [],
   "source": [
    "t['AntiKt4EMTopoJetsPt'].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d138d3d-93c6-4c89-84ea-78fdbf6d781f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
