{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # For quickly testing when working on external libraries\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopoCluster Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slightly different take on regression than what we've commonly being doing. Instead of making a network that will output the predicted topo-cluster energy, we will make one that will output the predicted *ratio* between true and reco energies.\n",
    "\n",
    "What's the difference? It might sound like a trivial change, but the ratio is a unitless quantity. So this might help with the problem of having to cover many orders of magnitude in outputs. Now, our \"classic\" regression networks were dealing with this by performing some scaling of inputs:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E_\\text{reco}  &\\rightarrow \\ln{ \\left (E_\\text{reco} \\right)} \\;, \\\\\n",
    "E_\\text{truth}  &\\rightarrow \\ln{ \\left (E_\\text{truth} \\right)} \\;\\; \\text{(target)},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The output of the network, $x$, is then converted to the predicted energy $E_\\text{pred}$ via the inverse transformation:\n",
    "\n",
    "$$\n",
    "x \\rightarrow e^{x} = E_\\text{pred}\n",
    "$$\n",
    "\n",
    "Thus if there's some small error in $x$, $x \\rightarrow x + \\delta x$, this may result in a large error in $E_\\text{pred}$:\n",
    "\n",
    "$$\n",
    "e^{x + \\delta x} = e^{\\delta x} E_\\text{pred} \\; .\n",
    "$$\n",
    "\n",
    "For example, if we're trying to get an energy of $100 \\, \\text{[GeV]}$ for a particular cluster, but our network ouput ($x$) is $10\\%$ too large, this will lead to a $\\sim 50\\%$ error in $E_\\text{pred}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML fitting/loading/saving settings\n",
    "overwriteModel = False # If true, force training. If false, load the specified model if it already exists.\n",
    "\n",
    "finishTraining = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose our training data (and associated strategy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'pion'\n",
    "subdir = 'pion5' # name for subdir holding models/plots\n",
    "h5_name_suffix = 'tdata_60GeV' # name for HDF5 files containing selected training/validation/testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we can define some training settings here for our different models. Note that we'll need to expand this if we add new models to the list.\n",
    "\n",
    "Also note that some model-specific settings are only adjusted further down in the code, where each model is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_settings = {\n",
    "    'all':{'lr':1.0e-5, 'epochs':200, 'patience':40, 'batch_size':200, 'skip':True},\n",
    "    'simple':{'lr':5.0e-5, 'epochs':200, 'patience':40, 'batch_size':200, 'skip':True},\n",
    "    'simple_cnn':{'lr':1.0e-4, 'epochs':200, 'patience':40, 'batch_size':200, 'skip':True},\n",
    "    'split_emb_cnn':{'lr':1.0e-4, 'epochs':200, 'patience':40, 'batch_size':200, 'skip':True},\n",
    "    'resnet':{'lr':1.0e-5, 'epochs':200, 'patience':40, 'batch_size':200, 'skip':True},\n",
    "    'lorentz':{'lr':1.0e-5, 'epochs':400, 'patience':300, 'batch_size':200, 'skip':False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 12:53:55.778983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# Import some basic libraries.\n",
    "import sys, os, glob, pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot as ur\n",
    "#import ROOT as rt # optionally used for plotting\n",
    "#import joblib as jl # for saving scalers\n",
    "\n",
    "# Import our resolution utilities\n",
    "path_prefix = os.getcwd() + '/../'\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import resolution_util as ru\n",
    "from util import plot_util       as pu\n",
    "from util import ml_util         as mu\n",
    "from util import qol_util        as qu\n",
    "from util import io_util         as iu\n",
    "\n",
    "# Custom tensorflow.keras callbacks\n",
    "from util.keras.callbacks import GetCallbacks\n",
    "\n",
    "# Regression-specific utils\n",
    "from util.regression import data_util as rdu\n",
    "from util.regression import plot_util as rpu\n",
    "from util.regression import training_util as rtu\n",
    "\n",
    "#rt.gStyle.SetOptStat(0)\n",
    "# use our custom dark style for plots\n",
    "plotstyle = qu.PlotStyle('dark')\n",
    "plotstyle.SetStyle() # still need to manually adjust legends, paves\n",
    "\n",
    "plotpath = path_prefix + 'regression2/Plots/{}/'.format(subdir)\n",
    "modelpath = path_prefix + 'regression2/Models/{}/'.format(subdir)\n",
    "paths = [plotpath, modelpath]\n",
    "for path in [plotpath, modelpath]:\n",
    "    try: os.makedirs(path)\n",
    "    except: pass\n",
    "\n",
    "# metadata\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "cell_shapes = {layers[i]:(len_eta[i],len_phi[i]) for i in range(len(layers))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy display names for each pion type\n",
    "pi_latex = {\n",
    "    'p0': '\\(\\pi^{0}\\)',\n",
    "    'pp': '\\(\\pi^{\\pm}\\)',\n",
    "}\n",
    "pi_text = {\n",
    "    'p0': 'pi0',\n",
    "    'pp': 'pi+/-'\n",
    "}\n",
    "\n",
    "# Plotting settings\n",
    "# xkcd -- turn this on for fun-looking (but marginally less useful) plots\n",
    "use_xkcd = False\n",
    "if(use_xkcd):\n",
    "    mode = 'light'\n",
    "    plt.xkcd(scale=.75,length=100,randomness=1)\n",
    "    \n",
    "# plotting style -- manages our color palette and object colors\n",
    "mode = 'dark' # for publications, use \"light\"\n",
    "plotstyle = qu.PlotStyle(mode)\n",
    "    \n",
    "# some matplotlib-specific stuff\n",
    "params = {'legend.fontsize': 13,\n",
    "          'axes.labelsize': 18}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Get the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me lay out some definitions, so it's clear as to what the data is.\n",
    "\n",
    "We have a number of different \"strategies\" (the `source` variable at the top). These correspond to different choices of training, validation and testing datasets.\n",
    "\n",
    "1. `pion`: We train and validate the network using our single pion data.\n",
    "\n",
    "2. `pion_legacy`: We train and validate using our old, noise-free single pion data.\n",
    "\n",
    "3. `pion_reweighted`: This is the same as `pion`, except that our training data is reweighted using a jet dataset (via their reco topo-cluster $p_T$ distributions), that corresponds with QCD dijet events.\n",
    "\n",
    "The validation performed for these networks is effectively being done on some \"holdout\" dataset from training -- it will by definition have similar kinematics, being drawn from the same set of events. The more interesting test -- how our energy regression performs in tandem with classification on our *unlabeled* jet dataset, will be handled in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(source == 'pion_legacy'):\n",
    "    inputpath = path_prefix+'data/pion_legacy/'\n",
    "    rootfiles = {\n",
    "        'p0':inputpath + 'pi0.root',\n",
    "        'pp':inputpath + 'pi[pm]*.root'\n",
    "    }\n",
    "    \n",
    "    branches = ['clusterE', 'clusterPt', 'clusterEta', 'cluster_ENG_CALIB_TOT']\n",
    "\n",
    "elif(source == 'pion' or source == 'pion_reweighted'):\n",
    "    inputpath=path_prefix+'data/pion/'\n",
    "    rootfiles = {        \n",
    "        'p0':inputpath + 'user.mswiatlo.900246.PG_singlepi0_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root',\n",
    "        'pp':inputpath + 'user.mswiatlo.900247.PG_singlepion_logE0p2to2000.recon.ESD.e8312_e7400_s3170_r12383.images_v01.1_OutputStream/*.root'\n",
    "    }\n",
    "    \n",
    "    branches = ['clusterE', 'clusterPt', 'clusterEta', 'cluster_ENG_CALIB_TOT']\n",
    "\n",
    "else: assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pandas DataFrame and calo images from /local/home/jano/ml4pions/LCStudies/regression2/../data/pion/tdata_60GeV_mini_frame.h5 and /local/home/jano/ml4pions/LCStudies/regression2/../data/pion/tdata_60GeV_mini_images.h5.\n",
      "Number of pi0     events:      50000\t(50.0%)\n",
      "Number of pi+/-   events:      50000\t(50.0%)\n",
      "Total: 100000\n",
      "Loading indices for key p0 from /local/home/jano/ml4pions/LCStudies/regression2/../data/pion/tdata_60GeV_mini_indices.h5.\n",
      "Loading indices for key pp from /local/home/jano/ml4pions/LCStudies/regression2/../data/pion/tdata_60GeV_mini_indices.h5.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "h5_name = inputpath + h5_name_suffix\n",
    "\n",
    "pdata,pcells = mu.setupPionData(\n",
    "    rootfiles, \n",
    "    branches=branches, \n",
    "    layers=layers, \n",
    "    balance_data=True, \n",
    "    n_max = 50000, # we usually use 300k, or 600k\n",
    "    verbose=True,\n",
    "    load=True,\n",
    "    save=True,\n",
    "    filename=h5_name,\n",
    "    match_distribution='cluster_ENG_CALIB_TOT',\n",
    "    match_binning = (20000,0.,2000.),\n",
    "    cut_distributions=['cluster_ENG_CALIB_TOT','clusterEta'],\n",
    "    cut_values = [(.2,60.), (-0.7,0.7)],\n",
    "    cut_types=['window','window'] # use only lower cut for \"standard\" training data\n",
    ")\n",
    "\n",
    "total = np.sum([len(x) for x in pdata.values()],dtype=int)\n",
    "for key,frame in pdata.items():\n",
    "    n = len(frame)\n",
    "    print(\"Number of {a:<7} events: {b:>10}\\t({c:.1f}%)\".format(a=pi_text[key], b = n, c = 100. * n / total))\n",
    "print(\"Total: {}\".format(total))\n",
    "\n",
    "# Create/get training/validation/testing indices.\n",
    "pdata = rdu.DataPrep(pdata,\n",
    "                     trainfrac=0.7,\n",
    "                     filename=h5_name\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining regression variables\n",
    "\n",
    "Beyond the information already present in the data, we may want to pre-compute some extra regression inputs.\n",
    "\n",
    "The difference between computing them here, on the whole dataset, versus doing it in batch as part of the network itself, is that we can also define some `scalers` based on these variables. This will allow us to scale them across the dataset, for example to get them into the interval of \\[0,1\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1.\n",
    "b = 1.\n",
    "EnergyMapping = iu.LinLogMapping(b=b,m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our `LinLogMapping` is pretty numerically stable as long as $b \\gg m$. I think this is the expected behaviour, given the instabilities with logarithms that we've seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some regression vars.\n",
    "# Note that the mapping functions can probably be sped up with numba, but might throw errors during plotting above. Need to look into this.\n",
    "for key,frame in pdata.items():\n",
    "    frame['logE'] = EnergyMapping.Forward(frame['clusterE'].to_numpy()) # log of reco energy, possible network input\n",
    "    frame['clusterEtaAbs'] = np.abs(frame['clusterEta'].to_numpy()) # absolute value of eta, possible network input\n",
    "    #frame['logECalib'] = EnergyMapping.Forward(frame['cluster_ENG_CALIB_TOT'].to_numpy()) # No longer our regression target\n",
    "\n",
    "    # Now get the ratio of \"truth\" to reco energy. Be mindful of zeros in denominator\n",
    "    x = frame['clusterE'].to_numpy()\n",
    "    x[x==0] = 1.\n",
    "    frame['ratioE'] = frame['cluster_ENG_CALIB_TOT'].to_numpy() / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scalers from /local/home/jano/ml4pions/LCStudies/regression2/../regression2/Models/pion5/scalers.save.\n"
     ]
    }
   ],
   "source": [
    "scaler_file = modelpath + 'scalers.save'\n",
    "scaler_branches = ['logE', 'clusterEtaAbs']\n",
    "scalers = mu.setupScalers(pdata, scaler_branches, scaler_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make plots of any vars that are rescaled using our StandardScalers, to see what the rescaling has done. (We won't put axis labels since the units are kind of funny anyway...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a histogram of the regression vars, before and after scaling.\n",
    "rvars = ['logE', 's_logE']\n",
    "ranges = {\n",
    "    'logE':(120,-2.,10.),\n",
    "    's_logE':(100,-2.,2.)\n",
    "}\n",
    "fig, ax = plt.subplots(1,len(rvars),figsize=(7.5 * len(rvars),5))\n",
    "if(type(ax) != np.ndarray): ax = [ax]\n",
    "\n",
    "for i,rvar in enumerate(rvars):\n",
    "    vals = {}\n",
    "    for key,frame in pdata.items():\n",
    "        vals[key] = frame[rvar].to_numpy()\n",
    "    pu.histogramOverlay(ax[i], vals.values(), list(vals.keys()), rvar, 'Fractional count',\n",
    "                        x_min = ranges[rvar][1], x_max = ranges[rvar][2], xbins = ranges[rvar][0],\n",
    "                        normed = True, y_log = True,\n",
    "                        ps = plotstyle\n",
    "                       )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make a plot of our regression target, to see what the distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a histogram of the regression vars, before and after scaling.\n",
    "rvars = ['ratioE']\n",
    "ranges = {\n",
    "    'ratioE':(200,0.,20.),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(1,len(rvars),figsize=(7.5 * len(rvars),5))\n",
    "if(type(ax) != np.ndarray): ax = [ax]\n",
    "\n",
    "for i,rvar in enumerate(rvars):\n",
    "    vals = {}\n",
    "    for key,frame in pdata.items():\n",
    "        vals[key] = frame[rvar].to_numpy()\n",
    "    pu.histogramOverlay(ax[i], vals.values(), list(vals.keys()), rvar, 'Fractional count',\n",
    "                        x_min = ranges[rvar][1], x_max = ranges[rvar][2], xbins = ranges[rvar][0],\n",
    "                        normed = True, y_log = True,\n",
    "                        ps = plotstyle\n",
    "                       )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we might have suspected, there is more spread for $\\pi^\\pm$ than for $\\pi^0$. In other words, the charged pion response is worse, and so it will make for a harder regression target. This is consistent with what we've seen elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may optionally perform some re-weighting of our training events. If using the `pion_reweighted` strategy, we will re-weight our single-pion training data to match the topo-cluster $p_T$ spectrum of our jet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consider re-adding some sample weighting schemes\n",
    "sample_weights = {\n",
    "    key: np.full(np.sum(frame['train'].to_numpy()),1.)\n",
    "    for key,frame in pdata.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow/Keras Prep\n",
    "\n",
    "In this workflow we have the ability to train a number of models -- some will require additional data setup. Here, we have some basic setup they will all use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {} # keep track of the models -- note that we train multiple instances of each model\n",
    "histories = {} # keep track of histories of the models we train\n",
    "regressors = {} # keep track of the trained models (will be KerasRegressor objects)\n",
    "energy_ratio_names = {} # keep track of the names of regressed variables\n",
    "\n",
    "model_filename_suffixes = {\n",
    "    'pp':'_charged',\n",
    "    'p0':'_neutral'\n",
    "}\n",
    "\n",
    "energy_name_prefix = 'ratio_pred_'\n",
    "\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor # scikit_learn wrapper -- why do we use this, vs. native tf.keras approach like in classification notebook?\n",
    "#from tensorflow.keras.models import load_model\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disable some of the tensorflow info printouts, only display errors\n",
    "import tensorflow as tf\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "#ngpu = strategy.num_replicas_in_sync\n",
    "#print ('Number of devices: {}'.format(ngpu))\n",
    "ngpu = 1\n",
    "\n",
    "#from util.regression.models import baseline_nn_All_model, simple_dnn, resnet, resnet_wide\n",
    "from util.regression.models import baseline_nn_model, depth_network, simple_cnn, split_emb_cnn, resnet, lorentz_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \"all\" model\n",
    "\n",
    "Here we train a simple, fully-connected neural network that uses the calorimeter cells as input, along with reco energy and $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "model_key = 'all'\n",
    "skip = training_settings[model_key]['skip']\n",
    "if(not skip):\n",
    "    print('Starting baseline model.')\n",
    "    \n",
    "    # Data preparation\n",
    "    All_input = rdu.CombinedInput(pdata,\n",
    "                                  pcells,\n",
    "                                  branches = ['s_logE','s_clusterEtaAbs']\n",
    "                                 )\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    decay = 0. # lr decay *within* each epoch\n",
    "    dropout = -1. # < 0 -> no dropout\n",
    "    models[model_key] = baseline_nn_model(lr=lr, decay=decay, dropout=dropout)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val'] \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = All_input[key][tidx],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = All_input[key][vidx],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \"simple\" (depth-based) model\n",
    "\n",
    "Here we train another simple, fully-connected neural network that uses reco energy and $\\eta$ as input, along with depth information (vector of integrals of calorimeter images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model\n",
    "model_key = 'simple'\n",
    "skip = training_settings[model_key]['skip']\n",
    "\n",
    "if(not skip):\n",
    "\n",
    "    print('Starting simple (depth-based) model.')\n",
    "    \n",
    "    # Data preparation.\n",
    "    All_input = rdu.DepthInput(pdata,\n",
    "                               pcells,\n",
    "                               branch_map = {\n",
    "                                   's_logE':'energy',\n",
    "                                   's_clusterEtaAbs':'eta'\n",
    "                               }\n",
    "                              )\n",
    "    Split_input = rdu.DictionarySplit(All_input, pdata)\n",
    "    train_input, valid_input = Split_input['train'], Split_input['val']\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    units = 32\n",
    "    depth = 8\n",
    "    decay = 0. # lr decay *within* each epoch\n",
    "    dropout = 0.05 # < 0 -> no dropout\n",
    "    models[model_key] = depth_network(lr=lr, decay=decay, dropout=dropout, units=units, depth=depth)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val']  \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = train_input[key],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = valid_input[key],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN\n",
    "\n",
    "This network uses some convolutions of the EMB layers, together with energy, eta and depth information (the depth info is computed internally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple CNN\n",
    "model_key = 'simple_cnn'\n",
    "skip = training_settings[model_key]['skip']\n",
    "\n",
    "if(not skip):\n",
    "    print('Starting simple CNN model.')\n",
    "    # Data preparation.\n",
    "    All_input = rdu.ResnetInput(pdata,\n",
    "                                pcells,\n",
    "                                branch_map = {\n",
    "                                    's_logE':'energy',\n",
    "                                    's_clusterEtaAbs':'eta'\n",
    "                                }\n",
    "    )\n",
    "    Split_input = rdu.DictionarySplit(All_input, pdata)\n",
    "    train_input, valid_input = Split_input['train'], Split_input['val']\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    decay = 0. # lr decay *within* each epoch\n",
    "    dropout = 0.2\n",
    "    augmentation = True # whether or not to augment data during training, by flipping in eta & phi\n",
    "    models[model_key] = simple_cnn(lr=lr, decay=decay, dropout=dropout, augmentation=augmentation)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val']  \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = train_input[key],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = valid_input[key],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split EMB CNN\n",
    "\n",
    "We can train a CNN model that's inspired by one of our well-performing CNN classifiers. It groups the 6 calo layers as EMB1, EMB2+EMB3, and TileBar0+TileBar1+TileBar2. Compared to the classifier, we've removed a few convolutions to make it a little simpler, and have added in energy and abs(eta) information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split EMB CNN (i.e. a more complicated CNN)\n",
    "model_key = 'split_emb_cnn'\n",
    "skip = training_settings[model_key]['skip']\n",
    "\n",
    "if(not skip):\n",
    "    print('\"Starting split EMB\" CNN model.')\n",
    "    \n",
    "    # Data preparation\n",
    "    All_input = rdu.ResnetInput(pdata,\n",
    "                                pcells,\n",
    "                                branch_map = {\n",
    "                                    's_logE':'energy',\n",
    "                                    's_clusterEtaAbs':'eta'\n",
    "                                }\n",
    "    )\n",
    "    Split_input = rdu.DictionarySplit(All_input, pdata)\n",
    "    train_input, valid_input = Split_input['train'], Split_input['val']\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    decay = 0. # lr decay *within* each epoch\n",
    "    dropout = 0.2\n",
    "    augmentation = True # whether or not to augment data during training, by flipping in eta & phi\n",
    "    models[model_key] = split_emb_cnn(lr=lr, decay=decay, dropout=dropout, augmentation=augmentation)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val']  \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = train_input[key],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = valid_input[key],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "We can also train an implementation of ResNet. More precisely, we use a ResNet model on the calorimeter images, and then mix in the energy and $\\eta$ at the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = 'resnet'\n",
    "skip = training_settings[model_key]['skip']\n",
    "\n",
    "if(not skip):\n",
    "\n",
    "    print('Starting ResNet.')\n",
    "    # Data preparation -- here we can possibly take a shortcut if this data was already prepared.\n",
    "    if(training_settings['split_emb_cnn']['skip']):\n",
    "        All_input = rdu.ResnetInput(pdata,\n",
    "                                    pcells,\n",
    "                                    branch_map = {\n",
    "                                        's_logE':'energy',\n",
    "                                        's_clusterEtaAbs':'eta'\n",
    "                                    }\n",
    "        )\n",
    "        Split_input = rdu.DictionarySplit(All_input, pdata)\n",
    "        train_input, valid_input = Split_input['train'], Split_input['val']\n",
    "    # ----------------------------------------------------------------    \n",
    "    \n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    decay = 0. # lr decay *within* each epoch 1e-6\n",
    "    channels = 6\n",
    "    filter_sets = [\n",
    "        [64,64,256],\n",
    "        [128,128,512]\n",
    "        #[256,256,1024],\n",
    "        #[512,512,2048]\n",
    "    ]         \n",
    "    f_vals = [3,3] # [3,3,3,3] sizes of filters in middle of conv/identity blocks\n",
    "    s_vals = [1,2] # [1,2,2,2] strides for each convolutional block\n",
    "    i_vals = [2,3] # [2,3,5,2] number of identity blocks per stage\n",
    "    input_shape = (128,16)\n",
    "    augmentation = True # whether or not to augment data during training, by flipping in eta & phi\n",
    "\n",
    "    models[model_key] = resnet(lr=lr, channels=channels, filter_sets=filter_sets, f_vals=f_vals, s_vals=s_vals, i_vals=i_vals, decay=decay, input_shape=input_shape, augmentation=augmentation)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val']  \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = train_input[key],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = valid_input[key],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LorentzNet\n",
    "\n",
    "Something experimental, let's see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not entirely sure why I now need this...\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LorentzNet.\n",
      "Preparing Lorentz input:  |\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m\u001b[32m█\u001b[0m| 100.0% Complete\n",
      "lorentz: pi0\n",
      "Epoch 1/100\n",
      "175/175 [==============================] - 11s 35ms/step - loss: 0.9986 - mae: 0.8806 - mse: 0.9986 - val_loss: 0.6687 - val_mae: 0.7909 - val_mse: 0.6687\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.6777 - mae: 0.6821 - mse: 0.6777 - val_loss: 0.3408 - val_mae: 0.5417 - val_mse: 0.3408\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.3223 - mae: 0.4114 - mse: 0.3223 - val_loss: 0.1332 - val_mae: 0.2910 - val_mse: 0.1332\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.1655 - mae: 0.2568 - mse: 0.1655 - val_loss: 0.0905 - val_mae: 0.2289 - val_mse: 0.0905\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.1094 - mae: 0.2223 - mse: 0.1094 - val_loss: 0.0787 - val_mae: 0.2146 - val_mse: 0.0787\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.1007 - mae: 0.2134 - mse: 0.1007 - val_loss: 0.0746 - val_mae: 0.2084 - val_mse: 0.0746\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0959 - mae: 0.2079 - mse: 0.0959 - val_loss: 0.0712 - val_mae: 0.2032 - val_mse: 0.0712\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0908 - mae: 0.2023 - mse: 0.0908 - val_loss: 0.0680 - val_mae: 0.1984 - val_mse: 0.0680\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0863 - mae: 0.1975 - mse: 0.0863 - val_loss: 0.0652 - val_mae: 0.1938 - val_mse: 0.0652\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0826 - mae: 0.1928 - mse: 0.0826 - val_loss: 0.0626 - val_mae: 0.1892 - val_mse: 0.0626\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0794 - mae: 0.1881 - mse: 0.0794 - val_loss: 0.0602 - val_mae: 0.1848 - val_mse: 0.0602\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0763 - mae: 0.1837 - mse: 0.0763 - val_loss: 0.0579 - val_mae: 0.1806 - val_mse: 0.0579\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0735 - mae: 0.1795 - mse: 0.0735 - val_loss: 0.0558 - val_mae: 0.1768 - val_mse: 0.0558\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0711 - mae: 0.1754 - mse: 0.0711 - val_loss: 0.0538 - val_mae: 0.1727 - val_mse: 0.0538\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0687 - mae: 0.1713 - mse: 0.0687 - val_loss: 0.0519 - val_mae: 0.1689 - val_mse: 0.0519\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0666 - mae: 0.1677 - mse: 0.0666 - val_loss: 0.0504 - val_mae: 0.1655 - val_mse: 0.0504\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0648 - mae: 0.1642 - mse: 0.0648 - val_loss: 0.0488 - val_mae: 0.1624 - val_mse: 0.0488\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0630 - mae: 0.1611 - mse: 0.0630 - val_loss: 0.0475 - val_mae: 0.1594 - val_mse: 0.0475\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0614 - mae: 0.1580 - mse: 0.0614 - val_loss: 0.0463 - val_mae: 0.1567 - val_mse: 0.0463\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0601 - mae: 0.1553 - mse: 0.0601 - val_loss: 0.0452 - val_mae: 0.1541 - val_mse: 0.0452\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0588 - mae: 0.1528 - mse: 0.0588 - val_loss: 0.0443 - val_mae: 0.1518 - val_mse: 0.0443\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0577 - mae: 0.1504 - mse: 0.0577 - val_loss: 0.0433 - val_mae: 0.1497 - val_mse: 0.0433\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0569 - mae: 0.1484 - mse: 0.0569 - val_loss: 0.0426 - val_mae: 0.1477 - val_mse: 0.0426\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0558 - mae: 0.1464 - mse: 0.0558 - val_loss: 0.0419 - val_mae: 0.1460 - val_mse: 0.0419\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0550 - mae: 0.1447 - mse: 0.0550 - val_loss: 0.0413 - val_mae: 0.1443 - val_mse: 0.0413\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0543 - mae: 0.1430 - mse: 0.0543 - val_loss: 0.0407 - val_mae: 0.1428 - val_mse: 0.0407\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0536 - mae: 0.1415 - mse: 0.0536 - val_loss: 0.0402 - val_mae: 0.1414 - val_mse: 0.0402\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0530 - mae: 0.1401 - mse: 0.0530 - val_loss: 0.0397 - val_mae: 0.1401 - val_mse: 0.0397\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0525 - mae: 0.1389 - mse: 0.0525 - val_loss: 0.0393 - val_mae: 0.1390 - val_mse: 0.0393\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0520 - mae: 0.1377 - mse: 0.0520 - val_loss: 0.0389 - val_mae: 0.1379 - val_mse: 0.0389\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0515 - mae: 0.1367 - mse: 0.0515 - val_loss: 0.0386 - val_mae: 0.1370 - val_mse: 0.0386\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0511 - mae: 0.1358 - mse: 0.0511 - val_loss: 0.0383 - val_mae: 0.1361 - val_mse: 0.0383\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0508 - mae: 0.1349 - mse: 0.0508 - val_loss: 0.0380 - val_mae: 0.1353 - val_mse: 0.0380\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0504 - mae: 0.1341 - mse: 0.0504 - val_loss: 0.0378 - val_mae: 0.1346 - val_mse: 0.0378\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0501 - mae: 0.1334 - mse: 0.0501 - val_loss: 0.0375 - val_mae: 0.1340 - val_mse: 0.0375\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0499 - mae: 0.1328 - mse: 0.0499 - val_loss: 0.0373 - val_mae: 0.1333 - val_mse: 0.0373\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0496 - mae: 0.1322 - mse: 0.0496 - val_loss: 0.0371 - val_mae: 0.1328 - val_mse: 0.0371\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0494 - mae: 0.1316 - mse: 0.0494 - val_loss: 0.0370 - val_mae: 0.1323 - val_mse: 0.0370\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0492 - mae: 0.1311 - mse: 0.0492 - val_loss: 0.0368 - val_mae: 0.1318 - val_mse: 0.0368\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0490 - mae: 0.1307 - mse: 0.0490 - val_loss: 0.0367 - val_mae: 0.1314 - val_mse: 0.0367\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0488 - mae: 0.1302 - mse: 0.0488 - val_loss: 0.0366 - val_mae: 0.1310 - val_mse: 0.0366\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0487 - mae: 0.1299 - mse: 0.0487 - val_loss: 0.0364 - val_mae: 0.1307 - val_mse: 0.0364\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0486 - mae: 0.1295 - mse: 0.0486 - val_loss: 0.0363 - val_mae: 0.1304 - val_mse: 0.0363\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0484 - mae: 0.1292 - mse: 0.0484 - val_loss: 0.0362 - val_mae: 0.1301 - val_mse: 0.0362\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0483 - mae: 0.1290 - mse: 0.0483 - val_loss: 0.0362 - val_mae: 0.1298 - val_mse: 0.0362\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0482 - mae: 0.1287 - mse: 0.0482 - val_loss: 0.0361 - val_mae: 0.1296 - val_mse: 0.0361\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0481 - mae: 0.1285 - mse: 0.0481 - val_loss: 0.0360 - val_mae: 0.1294 - val_mse: 0.0360\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0481 - mae: 0.1283 - mse: 0.0481 - val_loss: 0.0360 - val_mae: 0.1292 - val_mse: 0.0360\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0480 - mae: 0.1281 - mse: 0.0480 - val_loss: 0.0359 - val_mae: 0.1290 - val_mse: 0.0359\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0479 - mae: 0.1279 - mse: 0.0479 - val_loss: 0.0358 - val_mae: 0.1288 - val_mse: 0.0358\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0478 - mae: 0.1278 - mse: 0.0478 - val_loss: 0.0358 - val_mae: 0.1287 - val_mse: 0.0358\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0478 - mae: 0.1276 - mse: 0.0478 - val_loss: 0.0358 - val_mae: 0.1286 - val_mse: 0.0358\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0477 - mae: 0.1275 - mse: 0.0477 - val_loss: 0.0357 - val_mae: 0.1284 - val_mse: 0.0357\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0477 - mae: 0.1274 - mse: 0.0477 - val_loss: 0.0357 - val_mae: 0.1283 - val_mse: 0.0357\n",
      "Epoch 55/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0476 - mae: 0.1272 - mse: 0.0476 - val_loss: 0.0357 - val_mae: 0.1282 - val_mse: 0.0357\n",
      "Epoch 56/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0476 - mae: 0.1271 - mse: 0.0476 - val_loss: 0.0356 - val_mae: 0.1282 - val_mse: 0.0356\n",
      "Epoch 57/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0476 - mae: 0.1271 - mse: 0.0476 - val_loss: 0.0356 - val_mae: 0.1281 - val_mse: 0.0356\n",
      "Epoch 58/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0475 - mae: 0.1270 - mse: 0.0475 - val_loss: 0.0356 - val_mae: 0.1280 - val_mse: 0.0356\n",
      "Epoch 59/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0475 - mae: 0.1269 - mse: 0.0475 - val_loss: 0.0356 - val_mae: 0.1279 - val_mse: 0.0356\n",
      "Epoch 60/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0475 - mae: 0.1269 - mse: 0.0475 - val_loss: 0.0355 - val_mae: 0.1279 - val_mse: 0.0355\n",
      "Epoch 61/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0475 - mae: 0.1268 - mse: 0.0475 - val_loss: 0.0355 - val_mae: 0.1278 - val_mse: 0.0355\n",
      "Epoch 62/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0474 - mae: 0.1267 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1278 - val_mse: 0.0355\n",
      "Epoch 63/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0474 - mae: 0.1267 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1277 - val_mse: 0.0355\n",
      "Epoch 64/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0474 - mae: 0.1266 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1277 - val_mse: 0.0355\n",
      "Epoch 65/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0474 - mae: 0.1266 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1277 - val_mse: 0.0355\n",
      "Epoch 66/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0474 - mae: 0.1266 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1276 - val_mse: 0.0355\n",
      "Epoch 67/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0474 - mae: 0.1265 - mse: 0.0474 - val_loss: 0.0355 - val_mae: 0.1276 - val_mse: 0.0355\n",
      "Epoch 68/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1265 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1276 - val_mse: 0.0354\n",
      "Epoch 69/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1265 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 70/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1265 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 71/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 72/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 73/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 74/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1275 - val_mse: 0.0354\n",
      "Epoch 75/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 76/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 77/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1264 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 78/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1263 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 79/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1263 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 80/100\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0473 - mae: 0.1263 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 81/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0473 - mae: 0.1263 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Epoch 82/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0473 - mae: 0.1263 - mse: 0.0473 - val_loss: 0.0354 - val_mae: 0.1274 - val_mse: 0.0354\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "250/250 [==============================] - 6s 14ms/step\n",
      "lorentz: pi+/-\n",
      "Epoch 1/100\n",
      "175/175 [==============================] - 10s 33ms/step - loss: 1445.6202 - mae: 1.2926 - mse: 1445.6202 - val_loss: 1.8439 - val_mae: 1.0174 - val_mse: 1.8439\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 1627.2039 - mae: 1.1188 - mse: 1627.2039 - val_loss: 1.5037 - val_mae: 0.7971 - val_mse: 1.5037\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 2467.3464 - mae: 0.8779 - mse: 2467.3464 - val_loss: 1.7361 - val_mae: 0.4900 - val_mse: 1.7361\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 1140.1044 - mae: 0.5886 - mse: 1140.1044 - val_loss: 2.1031 - val_mae: 0.3945 - val_mse: 2.1031\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 527.8769 - mae: 0.4896 - mse: 527.8769 - val_loss: 2.1735 - val_mae: 0.3804 - val_mse: 2.1735\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 344.7943 - mae: 0.4577 - mse: 344.7943 - val_loss: 2.0750 - val_mae: 0.3757 - val_mse: 2.0750\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 212.0763 - mae: 0.4321 - mse: 212.0763 - val_loss: 1.9985 - val_mae: 0.3720 - val_mse: 1.9985\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 139.8667 - mae: 0.4140 - mse: 139.8667 - val_loss: 1.9411 - val_mae: 0.3687 - val_mse: 1.9411\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 96.1747 - mae: 0.4000 - mse: 96.1747 - val_loss: 1.8991 - val_mae: 0.3657 - val_mse: 1.8991\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 68.7921 - mae: 0.3890 - mse: 68.7921 - val_loss: 1.8752 - val_mae: 0.3630 - val_mse: 1.8752\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 46.9920 - mae: 0.3785 - mse: 46.9920 - val_loss: 1.8486 - val_mae: 0.3603 - val_mse: 1.8486\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 32.9769 - mae: 0.3699 - mse: 32.9769 - val_loss: 1.8414 - val_mae: 0.3582 - val_mse: 1.8414\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 24.2080 - mae: 0.3633 - mse: 24.2080 - val_loss: 1.8277 - val_mae: 0.3558 - val_mse: 1.8277\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 17.3907 - mae: 0.3568 - mse: 17.3907 - val_loss: 1.8244 - val_mae: 0.3541 - val_mse: 1.8244\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 12.8876 - mae: 0.3518 - mse: 12.8876 - val_loss: 1.8286 - val_mae: 0.3523 - val_mse: 1.8286\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 9.5097 - mae: 0.3471 - mse: 9.5097 - val_loss: 1.8138 - val_mae: 0.3505 - val_mse: 1.8138\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 7.1418 - mae: 0.3432 - mse: 7.1418 - val_loss: 1.8122 - val_mae: 0.3490 - val_mse: 1.8122\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 5.3644 - mae: 0.3395 - mse: 5.3644 - val_loss: 1.8094 - val_mae: 0.3476 - val_mse: 1.8094\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 4.0750 - mae: 0.3365 - mse: 4.0750 - val_loss: 1.8045 - val_mae: 0.3463 - val_mse: 1.8045\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 3s 16ms/step - loss: 3.1425 - mae: 0.3338 - mse: 3.1425 - val_loss: 1.8028 - val_mae: 0.3450 - val_mse: 1.8028\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 3s 17ms/step - loss: 2.4543 - mae: 0.3313 - mse: 2.4543 - val_loss: 1.8003 - val_mae: 0.3439 - val_mse: 1.8003\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 1.9519 - mae: 0.3292 - mse: 1.9519 - val_loss: 1.7969 - val_mae: 0.3428 - val_mse: 1.7969\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "250/250 [==============================] - 6s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 12:54:35.100742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-29 12:54:35.153064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro P5000 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 269.00GiB/s\n",
      "2021-07-29 12:54:35.153124: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-29 12:54:35.156748: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-29 12:54:35.156864: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-29 12:54:35.157750: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-29 12:54:35.158125: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-29 12:54:35.159830: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-29 12:54:35.160540: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-29 12:54:35.160733: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-29 12:54:35.162191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-29 12:54:35.164494: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-29 12:54:35.169858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: Quadro P5000 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 269.00GiB/s\n",
      "2021-07-29 12:54:35.173582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-29 12:54:35.173699: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-29 12:54:35.884518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-29 12:54:35.884552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-29 12:54:35.884558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-29 12:54:35.886346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15549 MB memory) -> physical GPU (device: 0, name: Quadro P5000, pci bus id: 0000:18:00.0, compute capability: 6.1)\n",
      "2021-07-29 12:54:41.138429: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-29 12:54:41.158257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n",
      "2021-07-29 12:54:45.385372: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-29 12:54:45.728495: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    }
   ],
   "source": [
    "model_key = 'lorentz'\n",
    "skip = training_settings[model_key]['skip']\n",
    "\n",
    "if(not skip):\n",
    "\n",
    "    print('Starting LorentzNet.')\n",
    "    n_vecs = 10 # needs to be set for both data prep and for the network\n",
    "    \n",
    "    # Data preparation.\n",
    "    All_input = rdu.LorentzInput(pdata,\n",
    "                                 pcells,\n",
    "                                 branch_map = {\n",
    "                                     's_logE':'energy',\n",
    "                                     's_clusterEtaAbs':'eta'\n",
    "                                 },\n",
    "                                 n_vecs=n_vecs\n",
    "                                )\n",
    "    Split_input = rdu.DictionarySplit(All_input, pdata)\n",
    "    train_input, valid_input = Split_input['train'], Split_input['val']\n",
    "    # ----------------------------------------------------------------    \n",
    "    \n",
    "    energy_ratio_names[model_key] = energy_name_prefix + model_key\n",
    "    lr = training_settings[model_key]['lr']\n",
    "    decay = 0. # lr decay *within* each epoch 1e-6\n",
    "   \n",
    "    models[model_key] = lorentz_net(lr=lr, n_vecs=n_vecs)\n",
    "\n",
    "    # Set our training hyper-parameters.\n",
    "    batch_size = training_settings[model_key]['batch_size']\n",
    "    epochs = training_settings[model_key]['epochs']\n",
    "    gamma = .1 # lr decay between epochs (via scheduler)\n",
    "    patience = training_settings[model_key]['patience']\n",
    "    min_delta = 0.0005\n",
    "    verbose = 1\n",
    "    regressors[model_key] = {}\n",
    "    histories[model_key] = {}\n",
    "\n",
    "    # Load/train the models, and evaluate them on all the data.\n",
    "    for key in All_input.keys():\n",
    "        print('{}: {}'.format(model_key, pi_text[key]))\n",
    "        tidx = pdata[key]['train']\n",
    "        vidx = pdata[key]['val']  \n",
    "\n",
    "        model_dir = ''.join([modelpath, model_key])\n",
    "        model_filename = '{}/{}{}.h5'.format(model_dir,model_key,model_filename_suffixes[key])\n",
    "\n",
    "        regressors[model_key][key], histories[model_key][key] = rtu.TrainNetwork(\n",
    "            model=models[model_key],\n",
    "            modelfile = model_filename,\n",
    "            x_train = train_input[key],\n",
    "            y_train = pdata[key]['ratioE'][tidx],\n",
    "            x_valid = valid_input[key],\n",
    "            y_valid = pdata[key]['ratioE'][vidx],\n",
    "            sample_weight=sample_weights[key],\n",
    "            callbacks = GetCallbacks(model_filename, append=True, use_decay=True, gamma=gamma, min_delta=min_delta, patience=patience), \n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            overwriteModel=overwriteModel,\n",
    "            finishTraining=finishTraining\n",
    "        )\n",
    "\n",
    "        # Get predictions for all the data.\n",
    "        pdata[key][energy_ratio_names[model_key]] = rtu.GetPredictions(regressor=regressors[model_key][key],\n",
    "                                                                       model_input = All_input[key],\n",
    "                                                                       indices = {k:pdata[key][k].to_numpy() for k in ['train','val','test']},\n",
    "                                                                       truth = pdata[key]['cluster_ENG_CALIB_TOT'].to_numpy(),\n",
    "                                                                       reco = pdata[key]['clusterE'].to_numpy(),\n",
    "                                                                       scaler = None,\n",
    "                                                                       mapping = None,\n",
    "                                                                       filename = model_filename.replace('.h5','_output.h5')\n",
    "                                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Mini\n",
    "\n",
    "In an effort to simplify our ResNet -- and get it to train faster -- we can consider just using a single channel for our images, or some subset of channels. We can re-use the input we prepared for our full ResNet, though we'll only need a portion of it. Note that if we only use a single channel, the rescaling (via `input_shape`) is redundant, and we should just set that to the original dimensions (and, in practice, remove the scaling entirely if we stick with just one channel).\n",
    "\n",
    "**TODO:** Reimplement this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results (testing how well our network works)\n",
    "\n",
    "Now, let's plot some kinematics and network results. We'll make two groups of plots -- one for charged pions and one for neutral pions.\n",
    "\n",
    "Within each group of plots, we'll make two plots for each quantity -- one made using just the training data, and then one made using all the data (training + whatever we excluded -- but still excluding events with `cluster_ENG_CALIB_TOT` $< 0$ since these blow up network output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience below\n",
    "training_frames = {key:frame[frame['train']] for key,frame in pdata.items()}\n",
    "validation_frames = {key:frame[frame['val']] for key,frame in pdata.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make plots of mse and mae for training and validation (if present)\n",
    "\n",
    "for model_key in histories.keys():\n",
    "    for dkey in histories[model_key].keys():\n",
    "    \n",
    "        dname = dkey\n",
    "        \n",
    "        epochs = len(histories[model_key][dkey]['mae'])\n",
    "        epoch_ticks = epochs\n",
    "        if(epoch_ticks > 10): epoch_ticks = epoch_ticks/2\n",
    "        x = np.arange(epochs) + 1\n",
    "        fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    \n",
    "        keys = ['mae','val_mae']\n",
    "        lines = [histories[model_key][dkey][key] for key in keys]\n",
    "        pu.multiplot_common(ax[0], x,lines, keys, y_min=1.0e-3, y_max=10., y_log=True, x_ticks=epoch_ticks, xlabel = 'Epoch', ylabel = 'MAE', title='Mean Avg. Error for {} ({})'.format(model_key,dname), ps=plotstyle)\n",
    "    \n",
    "        keys = ['mse','val_mse']\n",
    "        lines = [histories[model_key][dkey][key] for key in keys]\n",
    "        pu.multiplot_common(ax[1], x,lines, keys, y_min=1.0e-3, y_max=10., y_log=True, x_ticks=epoch_ticks, xlabel = 'Epoch', ylabel = 'MSE', title='Mean Sq. Error for {} ({})'.format(model_key,dname), ps=plotstyle)\n",
    "    \n",
    "        # add grids\n",
    "        for axis in ax.flatten():\n",
    "            axis.grid(True,color=plotstyle.grid_plt)\n",
    "\n",
    "        qu.SaveSubplots(fig, ax, ['mae_{}_{}'.format(model_key,dkey), 'mse_{}_{}'.format(model_key,dkey)], savedir=plotpath)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
